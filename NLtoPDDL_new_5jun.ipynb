{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give instructions of your domain in natural language. It could be a transcript, domain process manual or wikihow style instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste your input as unicode text here.\n",
    "\n",
    "instructions = u'''CURIOSITY MARS MISSION TRANSCRIPT\n",
    "\n",
    "The last stage of the launch vehicle gives the spacecraft a final push and spins it up for our eight-and-a-half month cruise to the red planet.\n",
    "\n",
    "10 minutes before hitting the atmosphere the cruise stage separates and final preparations for entry begin.\n",
    "\n",
    "Hitting the atmosphere at about 13000 miles per hour, the spacecraft begins to slow down. While slowing down, the spacecraft uses thrusters to help steer toward the landing target.\n",
    "\n",
    "We throw off weights to rebalance the spacecraft, so that it’s lined for parachute deploy. After slowing to about Mach 2, or about 1000 miles per hour, we deploy the parachute to slow down even further.\n",
    "\n",
    "Once we are below the speed of sound, the heat shield separates and the spacecraft looks for the ground with the landing radar.\n",
    "\n",
    "Once we reach an altitude of about 1 mile, the spacecraft drops out of the back-shell at about 200 miles an hour. It then fires up the landing engine to slow it down even further.\n",
    "\n",
    "Once we’ve descended to about 60 feet above the ground, and going only about 2 miles per hour, the rover separates from the descent stage. As the rover is lowered, the wheels deploy in preparation for landing.\n",
    "\n",
    "Once the rover is safely on the ground, and touchdown has been detected, the descent stage cuts the rover loose. It flies away leaving Curiosity safe on the surface of Mars.\n",
    "\n",
    "One of the first things Curiosity does after landing is to deploy the mast, which supports many cameras and instruments. Curiosity shoots a laser at an interesting target. This helps us quickly understand the kind and\n",
    "\n",
    "composition of that target from a distance of up to 30 feet.\n",
    "\n",
    "If the target is worth a closer look, the rover can drive up and inspect the target with instruments and tools at the end of its arm.\n",
    "\n",
    "The drill on the arm allows us to grab some of that rock and deliver it to the laboratory instruments inside the body of the rover.\n",
    "\n",
    "Those instruments can tell us even more about the mineral composition, getting us closer to understanding whether life could have existed on Mars.\n",
    "\n",
    "Curiosity will be exploring the red planet for at least 2 years and there’s no telling what we will discover.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURIOSITY MARS MISSION TRANSCRIPT\n",
      "The last stage of the launch vehicle gives the spacecraft a final push and spins it up for our eight-and-a-half month cruise to the red planet.\n",
      "10 minutes before hitting the atmosphere the cruise stage separates and final preparations for entry begin.\n",
      "Hitting the atmosphere at about 13000 miles per hour, the spacecraft begins to slow down. While slowing down, the spacecraft uses thrusters to help steer toward the landing target.\n",
      "We throw off weights to rebalance the spacecraft, so that it’s lined for parachute deploy. After slowing to about Mach 2, or about 1000 miles per hour, we deploy the parachute to slow down even further.\n",
      "Once we are below the speed of sound, the heat shield separates and the spacecraft looks for the ground with the landing radar.\n",
      "Once we reach an altitude of about 1 mile, the spacecraft drops out of the back-shell at about 200 miles an hour. It then fires up the landing engine to slow it down even further.\n",
      "Once we’ve descended to about 60 feet above the ground, and going only about 2 miles per hour, the rover separates from the descent stage. As the rover is lowered, the wheels deploy in preparation for landing.\n",
      "Once the rover is safely on the ground, and touchdown has been detected, the descent stage cuts the rover loose. It flies away leaving Curiosity safe on the surface of Mars.\n",
      "One of the first things Curiosity does after landing is to deploy the mast, which supports many cameras and instruments. Curiosity shoots a laser at an interesting target. This helps us quickly understand the kind and\n",
      "composition of that target from a distance of up to 30 feet.\n",
      "If the target is worth a closer look, the rover can drive up and inspect the target with instruments and tools at the end of its arm.\n",
      "The drill on the arm allows us to grab some of that rock and deliver it to the laboratory instruments inside the body of the rover.\n",
      "Those instruments can tell us even more about the mineral composition, getting us closer to understanding whether life could have existed on Mars.\n",
      "Curiosity will be exploring the red planet for at least 2 years and there’s no telling what we will discover.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove empty lines from input instructions -- this is important for BERT which looks at previous and forward sentences.\n",
    "valid_instructions = ''\n",
    "lines = instructions.split(\"\\n\")\n",
    "non_empty_lines = [line for line in lines if line.strip() != \"\"]\n",
    "for line in non_empty_lines:\n",
    "      valid_instructions += line + u\"\\n\"\n",
    "print(valid_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove pronoun coreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURIOSITY MARS MISSION TRANSCRIPT\n",
      "The last stage of the launch vehicle gives the spacecraft a final push and spins the spacecraft up for our eight-and-a-half month cruise to the red planet.\n",
      "10 minutes before hitting the atmosphere the cruise stage separates and final preparations for entry begin.\n",
      "Hitting the atmosphere at about 13000 miles per hour, the spacecraft begins to slow down. While slowing down, the spacecraft uses thrusters to help steer toward the landing target.\n",
      "We throw off weights to rebalance the spacecraft, so that the spacecraft’s lined for parachute deploy. After slowing to about Mach 2, or about 1000 miles per hour, we deploy the parachute to slow down even further.\n",
      "Once we are below the speed of sound, the heat shield separates and the spacecraft looks for the ground with the landing radar.\n",
      "Once we reach an altitude of about 1 mile, the spacecraft drops out of the back-shell at about 200 miles an hour. the spacecraft then fires up the landing engine to slow the landing engine down even further.\n",
      "Once we’ve descended to about 60 feet above the ground, and going only about 2 miles per hour, the rover separates from the descent stage. As the rover is lowered, the wheels deploy in preparation for landing.\n",
      "Once the rover is safely on the ground, and touchdown has been detected, the descent stage cuts the rover loose. the descent stage flies away leaving Curiosity safe on the surface of Mars.\n",
      "One of the first things Curiosity does after landing is to deploy the mast, which supports many cameras and instruments. Curiosity shoots a laser at an interesting target. This helps us quickly understand the kind and\n",
      "composition of an interesting target from a distance of up to 30 feet.\n",
      "If an interesting target is worth a closer look, the rover can drive up and inspect an interesting target with instruments and tools at the end of the rover arm.\n",
      "The drill on its arm allows us to grab some of that rock and deliver some of that rock to the laboratory instruments inside the body of the rover.\n",
      "the laboratory instruments inside the body of the rover can tell us even more about the mineral composition, getting us closer to understanding whether life could have existed on Mars.\n",
      "Curiosity will be exploring the red planet for at least 2 years and there’s no telling what we will discover.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "doc1 = nlp(valid_instructions)\n",
    "coref_resolved_instructions =  doc1._.coref_resolved\n",
    "\n",
    "print(coref_resolved_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write the file into proper directory to be run by main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'nasa_curiosity.txt'\n",
    "main_file_name = 'main_ceasdrl.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace input filename in the main file\n",
    "import re\n",
    "\n",
    "# Read in the file\n",
    "with open(main_file_name, 'r') as file :\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = re.sub(r'input_filename = .*txt', \"input_filename = '\"+ fname, filedata)\n",
    "\n",
    "# Write the file out again\n",
    "with open(main_file_name, 'w') as file:\n",
    "    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURIOSITY MARS MISSION TRANSCRIPT\n",
      "The last stage of the launch vehicle gives the spacecraft a final push and spins the spacecraft up for our eight-and-a-half month cruise to the red planet.\n",
      "10 minutes before hitting the atmosphere the cruise stage separates and final preparations for entry begin.\n",
      "Hitting the atmosphere at about 13000 miles per hour, the spacecraft begins to slow down. While slowing down, the spacecraft uses thrusters to help steer toward the landing target.\n",
      "We throw off weights to rebalance the spacecraft, so that the spacecraft’s lined for parachute deploy. After slowing to about Mach 2, or about 1000 miles per hour, we deploy the parachute to slow down even further.\n",
      "Once we are below the speed of sound, the heat shield separates and the spacecraft looks for the ground with the landing radar.\n",
      "Once we reach an altitude of about 1 mile, the spacecraft drops out of the back-shell at about 200 miles an hour. the spacecraft then fires up the landing engine to slow the landing engine down even further.\n",
      "Once we’ve descended to about 60 feet above the ground, and going only about 2 miles per hour, the rover separates from the descent stage. As the rover is lowered, the wheels deploy in preparation for landing.\n",
      "Once the rover is safely on the ground, and touchdown has been detected, the descent stage cuts the rover loose. the descent stage flies away leaving Curiosity safe on the surface of Mars.\n",
      "One of the first things Curiosity does after landing is to deploy the mast, which supports many cameras and instruments. Curiosity shoots a laser at an interesting target. This helps us quickly understand the kind and\n",
      "composition of an interesting target from a distance of up to 30 feet.\n",
      "If an interesting target is worth a closer look, the rover can drive up and inspect an interesting target with instruments and tools at the end of the rover arm.\n",
      "The drill on its arm allows us to grab some of that rock and deliver some of that rock to the laboratory instruments inside the body of the rover.\n",
      "the laboratory instruments inside the body of the rover can tell us even more about the mineral composition, getting us closer to understanding whether life could have existed on Mars.\n",
      "Curiosity will be exploring the red planet for at least 2 years and there’s no telling what we will discover.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Writing the instructions file into directory\n",
    "# Writing the file\n",
    "text_file = open(\"./data/process_manuals/\" + fname, \"w\")\n",
    "text_file.write(coref_resolved_instructions)\n",
    "text_file.close()\n",
    "\n",
    "# Reading the file\n",
    "text_file = open(\"./data/process_manuals/\" + fname, \"r\")\n",
    "print(text_file.read())\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract action sequence by running c-EASDRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From main_ceasdrl.py:3: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From main_ceasdrl.py:115: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-07-06 01:03:59.463938: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Initializing the Environment...\n",
      "Initializing the DQN...\n",
      "WARNING:tensorflow:From /Users/shivam/.virtualenvs/contextual_drl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500, 6344, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 499, 1, 32)   406048      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 498, 1, 32)   609056      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 497, 1, 32)   812064      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 496, 1, 32)   1015072     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 499, 1, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 498, 1, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 497, 1, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 496, 1, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 4, 32)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          33024       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            514         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,875,778\n",
      "Trainable params: 2,875,778\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Initializing the Environment...\n",
      "Initializing the DQN...\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100, 2604, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 99, 1, 32)    166688      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 98, 1, 32)    250016      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 97, 1, 32)    333344      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 1, 32)    416672      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 99, 1, 32)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 98, 1, 32)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 97, 1, 32)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 1, 32)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 32)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 4, 32)     0           max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          33024       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            514         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,200,258\n",
      "Trainable params: 1,200,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Loading weights ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from weights/wikihow_act_bert.h5 ...\n",
      "Loaded weights from weights/wikihow_arg_elmo.h5 ...\n",
      "weights loaded ...\n",
      "CURIOSITY MARS MISSION TRANSCRIPT\n",
      "The last stage of the launch vehicle gives the spacecraft a final push and spins the spacecraft up for our eight-and-a-half month cruise to the red planet.\n",
      "10 minutes before hitting the atmosphere the cruise stage separates and final preparations for entry begin.\n",
      "Hitting the atmosphere at about 13000 miles per hour, the spacecraft begins to slow down. While slowing down, the spacecraft uses thrusters to help steer toward the landing target.\n",
      "We throw off weights to rebalance the spacecraft, so that the spacecraft’s lined for parachute deploy. After slowing to about Mach 2, or about 1000 miles per hour, we deploy the parachute to slow down even further.\n",
      "Once we are below the speed of sound, the heat shield separates and the spacecraft looks for the ground with the landing radar.\n",
      "Once we reach an altitude of about 1 mile, the spacecraft drops out of the back-shell at about 200 miles an hour. the spacecraft then fires up the landing engine to slow the landing engine down even further.\n",
      "Once we’ve descended to about 60 feet above the ground, and going only about 2 miles per hour, the rover separates from the descent stage. As the rover is lowered, the wheels deploy in preparation for landing.\n",
      "Once the rover is safely on the ground, and touchdown has been detected, the descent stage cuts the rover loose. the descent stage flies away leaving Curiosity safe on the surface of Mars.\n",
      "One of the first things Curiosity does after landing is to deploy the mast, which supports many cameras and instruments. Curiosity shoots a laser at an interesting target. This helps us quickly understand the kind and\n",
      "composition of an interesting target from a distance of up to 30 feet.\n",
      "If an interesting target is worth a closer look, the rover can drive up and inspect an interesting target with instruments and tools at the end of the rover arm.\n",
      "The drill on its arm allows us to grab some of that rock and deliver some of that rock to the laboratory instruments inside the body of the rover.\n",
      "the laboratory instruments inside the body of the rover can tell us even more about the mineral composition, getting us closer to understanding whether life could have existed on Mars.\n",
      "Curiosity will be exploring the red planet for at least 2 years and there’s no telling what we will discover.\n",
      " \n",
      "100%|███████████████████████████████████████████| 22/22 [00:02<00:00,  7.56it/s]\n",
      "WARNING:tensorflow:From /Users/shivam/.virtualenvs/contextual_drl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "\n",
      "NO1: Curiosity(1) mars(2) mission(3) transcript(4) \n",
      "\n",
      "NO2: The(1) last(2) stage(3) of(4) the(5) launch(6) vehicle(7) gives(8) the(9) spacecraft(10) a(11) final(12) push(13) and(14) spins(15) the(16) spacecraft(17) up(18) for(19) our(20) eight-and-a-half(21) month(22) cruise(23) to(24) the(25) red(26) planet.(27) \n",
      "<1>  spins (spacecraft)    \n",
      "\n",
      "NO3: 10(1) minutes(2) before(3) hitting(4) the(5) atmosphere(6) the(7) cruise(8) stage(9) separates(10) and(11) final(12) preparations(13) for(14) entry(15) begin.(16) \n",
      "\n",
      "NO4: Hitting(1) the(2) atmosphere(3) at(4) about(5) 13000(6) miles(7) per(8) hour(9) the(10) spacecraft(11) begins(12) to(13) slow(14) down(15) \n",
      "\n",
      "NO5: While(1) slowing(2) down(3) the(4) spacecraft(5) uses(6) thrusters(7) to(8) help(9) steer(10) toward(11) the(12) landing(13) target.(14) \n",
      "<2>  slowing (spacecraft, thrusters)    <3>  uses (thrusters)    \n",
      "\n",
      "NO6: We(1) throw(2) off(3) weights(4) to(5) rebalance(6) the(7) spacecraft(8) so(9) that(10) the(11) spacecraft’s(12) lined(13) for(14) parachute(15) deploy(16) \n",
      "<4>  throw (weights)    <5>  rebalance (spacecraft)    \n",
      "\n",
      "NO7: After(1) slowing(2) to(3) about(4) Mach(5) 2(6) or(7) about(8) 1000(9) miles(10) per(11) hour(12) we(13) deploy(14) the(15) parachute(16) to(17) slow(18) down(19) even(20) further.(21) \n",
      "<6>  slowing (Mach)    <7>  deploy (parachute)    <8>  slow ()    \n",
      "\n",
      "NO8: Once(1) we(2) are(3) below(4) the(5) speed(6) of(7) sound(8) the(9) heat(10) shield(11) separates(12) and(13) the(14) spacecraft(15) looks(16) for(17) the(18) ground(19) with(20) the(21) landing(22) radar.(23) \n",
      "\n",
      "NO9: Once(1) we(2) reach(3) an(4) altitude(5) of(6) about(7) 1(8) mile(9) the(10) spacecraft(11) drops(12) out(13) of(14) the(15) back-shell(16) at(17) about(18) 200(19) miles(20) an(21) hour(22) \n",
      "<9>  reach (altitude)    \n",
      "\n",
      "NO10: the(1) spacecraft(2) then(3) fires(4) up(5) the(6) landing(7) engine(8) to(9) slow(10) the(11) landing(12) engine(13) down(14) even(15) further.(16) \n",
      "<10>  fires (landing, engine)    <11>  slow (landing, engine)    \n",
      "\n",
      "NO11: Once(1) we’ve(2) descended(3) to(4) about(5) 60(6) feet(7) above(8) the(9) ground(10) and(11) going(12) only(13) about(14) 2(15) miles(16) per(17) hour(18) the(19) rover(20) separates(21) from(22) the(23) descent(24) stage(25) \n",
      "\n",
      "NO12: As(1) the(2) rover(3) is(4) lowered(5) the(6) wheels(7) deploy(8) in(9) preparation(10) for(11) landing.(12) \n",
      "<12>  lowered (wheels)    <13>  deploy (preparation)    \n",
      "\n",
      "NO13: Once(1) the(2) rover(3) is(4) safely(5) on(6) the(7) ground(8) and(9) touchdown(10) has(11) been(12) detected(13) the(14) descent(15) stage(16) cuts(17) the(18) rover(19) loose(20) \n",
      "\n",
      "NO14: the(1) descent(2) stage(3) flies(4) away(5) leaving(6) Curiosity(7) safe(8) on(9) the(10) surface(11) of(12) Mars.(13) \n",
      "\n",
      "NO15: One(1) of(2) the(3) first(4) things(5) Curiosity(6) does(7) after(8) landing(9) is(10) to(11) deploy(12) the(13) mast(14) which(15) supports(16) many(17) cameras(18) and(19) instruments(20) \n",
      "<14>  deploy (mast)    \n",
      "\n",
      "NO16: Curiosity(1) shoots(2) a(3) laser(4) at(5) an(6) interesting(7) target(8) \n",
      "\n",
      "NO17: This(1) helps(2) us(3) quickly(4) understand(5) the(6) kind(7) and(8) \n",
      "\n",
      "NO18: composition(1) of(2) an(3) interesting(4) target(5) from(6) a(7) distance(8) of(9) up(10) to(11) 30(12) feet.(13) \n",
      "<15>  composition (target)    \n",
      "\n",
      "NO19: If(1) an(2) interesting(3) target(4) is(5) worth(6) a(7) closer(8) look(9) the(10) rover(11) can(12) drive(13) up(14) and(15) inspect(16) an(17) interesting(18) target(19) with(20) instruments(21) and(22) tools(23) at(24) the(25) end(26) of(27) the(28) rover(29) arm.(30) \n",
      "<16>  inspect (target)    \n",
      "\n",
      "NO20: The(1) drill(2) on(3) its(4) arm(5) allows(6) us(7) to(8) grab(9) some(10) of(11) that(12) rock(13) and(14) deliver(15) some(16) of(17) that(18) rock(19) to(20) the(21) laboratory(22) instruments(23) inside(24) the(25) body(26) of(27) the(28) rover.(29) \n",
      "<17>  grab (rock)    <18>  deliver (rock)    \n",
      "\n",
      "NO21: the(1) laboratory(2) instruments(3) inside(4) the(5) body(6) of(7) the(8) rover(9) can(10) tell(11) us(12) even(13) more(14) about(15) the(16) mineral(17) composition(18) getting(19) us(20) closer(21) to(22) understanding(23) whether(24) life(25) could(26) have(27) existed(28) on(29) Mars.(30) \n",
      "\n",
      "NO22: Curiosity(1) will(2) be(3) exploring(4) the(5) red(6) planet(7) for(8) at(9) least(10) 2(11) years(12) and(13) there’s(14) no(15) telling(16) what(17) we(18) will(19) discover.(20) \n",
      "<19>  discover. ()    \n",
      "\n",
      "===========================\n",
      "\n",
      "spins (spacecraft),slowing (spacecraft, thrusters),uses (thrusters),throw (weights),rebalance (spacecraft),slowing (Mach),deploy (parachute),slow (),reach (altitude),fires (landing, engine),slow (landing, engine),lowered (wheels),deploy (preparation),deploy (mast),composition (target),inspect (target),grab (rock),deliver (rock),discover. ()\n"
     ]
    }
   ],
   "source": [
    "# don't forget to switch the dataset between cooking and wikihow\n",
    "!python -W ignore main_ceasdrl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the domain model in PDDL using iLOCM\n",
    "\n",
    "**interactive-LOCM**\n",
    "This code combines LOCM1 and LOCM2 algorithms and is last part of the pipeline that I use in my thesis to generate PDDL models from instructional texts.\n",
    "\n",
    "- Step 0: Preprocess: Lemmatize, Coref resolve, action override rename and replacing empty parameters.\n",
    "- Step 1: Find classes and make transition graphs.\n",
    "- Step 2: Get transistion sets from LOCM2 algorithm\n",
    "- Step 3: Create FSMs\n",
    "- Step 4: Perform Zero Analysis and add new FSM if necessary.\n",
    "- Step 5: Create and test hypothesis for state parameters\n",
    "- Step 6: Create and merge state parameters\n",
    "- Step 7: Remove parameter flaws\n",
    "- Step 8: Extract static preconditions\n",
    "- Step 9: Form action schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "from IPython.display import display, Markdown\n",
    "from ipycytoscape import *\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = \"locm_data/\"+fname\n",
    "domain_name = input_file_name.split('/')[-1].split('.')[0] #domain name is the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nasa_curiosity\n"
     ]
    }
   ],
   "source": [
    "print(domain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(input_file_name):\n",
    "    '''\n",
    "    Read the input data and return list of action sequences.\n",
    "    Each sequence is a list of action-argumentlist tuples.\n",
    "    '''\n",
    "    file = open(input_file_name, 'r')\n",
    "    sequences = []\n",
    "    for line in file:\n",
    "        \n",
    "        actions = []\n",
    "        arguments = []\n",
    "        if line and not line.isspace() and len(line)>1:\n",
    "            sequence = line.rstrip(\"\\n\\r\").lstrip(\"\\n\\r\").lower() \n",
    "            action_defs = sequence.split(\"),\")\n",
    "\n",
    "            for action_def in action_defs:\n",
    "                action = action_def.split('(')[0].strip(\")\\n\\r\").strip()\n",
    "                argument = action_def.split('(')[1].strip(\")\\n\\r\")\n",
    "                actions.append(action.translate(str.maketrans('', '', string.punctuation)))\n",
    "                argument_list = argument.split(',')\n",
    "                argument_list = [x.strip() for x in argument_list]\n",
    "                #argument_list.insert(0,'zero')\n",
    "                arguments.append(argument_list)\n",
    "                \n",
    "            \n",
    "            actarg_tuples = zip(actions,arguments)\n",
    "            sequences.append(list(actarg_tuples))\n",
    "    return sequences\n",
    "\n",
    "def print_sequences(sequences):\n",
    "    for seq in sequences:\n",
    "        for index,action in enumerate(seq):\n",
    "            print(str(index) + \": \" + str(action))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-79acb3279f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_file' is not defined"
     ]
    }
   ],
   "source": [
    "sequences = read_file(input_file_name)\n",
    "print_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize action sequences by lemmatization of extracted actions and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('boardtruck', ['driver1', 'truck2', 's4'])\n",
      "1: ('loadtruck', ['package5', 'truck2', 's4'])\n",
      "2: ('drivetruck', ['truck2', 's4', 's1', 'driver1'])\n",
      "3: ('drivetruck', ['truck2', 's1', 's3', 'driver1'])\n",
      "4: ('unloadtruck', ['package5', 'truck2', 's3'])\n",
      "5: ('drivetruck', ['truck2', 's3', 's5', 'driver1'])\n",
      "6: ('drivetruck', ['truck2', 's5', 's1', 'driver1'])\n",
      "7: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "8: ('boardtruck', ['driver2', 'truck1', 's0'])\n",
      "9: ('loadtruck', ['package2', 'truck1', 's0'])\n",
      "10: ('drivetruck', ['truck1', 's0', 's1', 'driver2'])\n",
      "11: ('unloadtruck', ['package2', 'truck1', 's1'])\n",
      "12: ('drivetruck', ['truck1', 's1', 's0', 'driver2'])\n",
      "13: ('disembarktruck', ['driver2', 'truck1', 's0'])\n",
      "14: ('boardtruck', ['driver1', 'truck2', 's1'])\n",
      "15: ('loadtruck', ['package1', 'truck2', 's1'])\n",
      "16: ('drivetruck', ['truck2', 's1', 's4', 'driver1'])\n",
      "17: ('drivetruck', ['truck2', 's4', 's5', 'driver1'])\n",
      "18: ('unloadtruck', ['package1', 'truck2', 's5'])\n",
      "19: ('drivetruck', ['truck2', 's5', 's1', 'driver1'])\n",
      "20: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "21: ('boardtruck', ['driver1', 'truck2', 's1'])\n",
      "22: ('drivetruck', ['truck2', 's1', 's4', 'driver1'])\n",
      "23: ('loadtruck', ['package4', 'truck2', 's4'])\n",
      "24: ('drivetruck', ['truck2', 's4', 's1', 'driver1'])\n",
      "25: ('unloadtruck', ['package4', 'truck2', 's1'])\n",
      "26: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "27: ('boardtruck', ['driver1', 'truck2', 's1'])\n",
      "28: ('drivetruck', ['truck2', 's1', 's4', 'driver1'])\n",
      "29: ('loadtruck', ['package3', 'truck2', 's4'])\n",
      "30: ('drivetruck', ['truck2', 's4', 's5', 'driver1'])\n",
      "31: ('unloadtruck', ['package3', 'truck2', 's5'])\n",
      "32: ('drivetruck', ['truck2', 's5', 's1', 'driver1'])\n",
      "33: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normalize the words by lemmatization\n",
    "# ps = PorterStemmer()\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "new_sequences = []\n",
    "\n",
    "for seq in sequences:\n",
    "    acts = []\n",
    "    arg_lists = []\n",
    "    for index,action in enumerate(seq):\n",
    "        act = wordnet_lemmatizer.lemmatize(action[0],pos='v')\n",
    "        acts.append(act)\n",
    "        arg_list = [wordnet_lemmatizer.lemmatize(arg, pos='n') for arg in action[1]]\n",
    "        arg_lists.append(arg_list)\n",
    "    act_arg_tups = zip(acts,arg_lists)\n",
    "    new_sequences.append(list(act_arg_tups))\n",
    "\n",
    "\n",
    "print_sequences(new_sequences)\n",
    "sequences = new_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename actions with same name but different arguments by appending a counter to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since action always have one argument, consider '' as an implicit one argument. Not renaming such actions.\n",
    "# renaming 1 or more clashing action prototypes \n",
    "\n",
    "\n",
    "all_tuples_in_all_seqs = []\n",
    "for seq in sequences:\n",
    "    for index,action in enumerate(seq):\n",
    "        all_tuples_in_all_seqs.append((action[0],len(action[1])))\n",
    "        \n",
    "all_act_len_set = set(all_tuples_in_all_seqs) # set of all actions with their arglist lens\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "for k, v in all_act_len_set:\n",
    "    d[k].append(v) #dictionary of list of lens for each key\n",
    "\n",
    "# keys with list len > 1 have clashing action names\n",
    "clashing_action_tuples = []     \n",
    "for k,v in d.items():\n",
    "    if len(d[k]) > 1:\n",
    "        for index,val in enumerate(d[k]):\n",
    "            if index > 0:\n",
    "                clashing_action_tuples.append((k,val,index))\n",
    "                \n",
    "\n",
    "# replace all clashing action tuples in original sequences\n",
    "\n",
    "\n",
    "for clashing_tup in clashing_action_tuples:\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for j, actarg_tup in enumerate(seq):\n",
    "            if (clashing_tup[0] == actarg_tup[0]) and clashing_tup[1] == len(actarg_tup[1]):\n",
    "                sequences[i][j] = (sequences[i][j][0]+str(clashing_tup[2]), sequences[i][j][1])\n",
    "                \n",
    "\n",
    "# replace all '' parameters with '#'\n",
    "for i, seq in enumerate(sequences):\n",
    "    for j, actarg_tup in enumerate(seq):\n",
    "        sequences[i][j] = (sequences[i][j][0], ['#' if x=='' else x for x in sequences[i][j][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ('boardtruck', ['driver1', 'truck2', 's4'])\n",
      "1: ('loadtruck', ['package5', 'truck2', 's4'])\n",
      "2: ('drivetruck', ['truck2', 's4', 's1', 'driver1'])\n",
      "3: ('drivetruck', ['truck2', 's1', 's3', 'driver1'])\n",
      "4: ('unloadtruck', ['package5', 'truck2', 's3'])\n",
      "5: ('drivetruck', ['truck2', 's3', 's5', 'driver1'])\n",
      "6: ('drivetruck', ['truck2', 's5', 's1', 'driver1'])\n",
      "7: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "8: ('boardtruck', ['driver2', 'truck1', 's0'])\n",
      "9: ('loadtruck', ['package2', 'truck1', 's0'])\n",
      "10: ('drivetruck', ['truck1', 's0', 's1', 'driver2'])\n",
      "11: ('unloadtruck', ['package2', 'truck1', 's1'])\n",
      "12: ('drivetruck', ['truck1', 's1', 's0', 'driver2'])\n",
      "13: ('disembarktruck', ['driver2', 'truck1', 's0'])\n",
      "14: ('boardtruck', ['driver1', 'truck2', 's1'])\n",
      "15: ('loadtruck', ['package1', 'truck2', 's1'])\n",
      "16: ('drivetruck', ['truck2', 's1', 's4', 'driver1'])\n",
      "17: ('drivetruck', ['truck2', 's4', 's5', 'driver1'])\n",
      "18: ('unloadtruck', ['package1', 'truck2', 's5'])\n",
      "19: ('drivetruck', ['truck2', 's5', 's1', 'driver1'])\n",
      "20: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "21: ('boardtruck', ['driver1', 'truck2', 's1'])\n",
      "22: ('drivetruck', ['truck2', 's1', 's4', 'driver1'])\n",
      "23: ('loadtruck', ['package4', 'truck2', 's4'])\n",
      "24: ('drivetruck', ['truck2', 's4', 's1', 'driver1'])\n",
      "25: ('unloadtruck', ['package4', 'truck2', 's1'])\n",
      "26: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "27: ('boardtruck', ['driver1', 'truck2', 's1'])\n",
      "28: ('drivetruck', ['truck2', 's1', 's4', 'driver1'])\n",
      "29: ('loadtruck', ['package3', 'truck2', 's4'])\n",
      "30: ('drivetruck', ['truck2', 's4', 's5', 'driver1'])\n",
      "31: ('unloadtruck', ['package3', 'truck2', 's5'])\n",
      "32: ('drivetruck', ['truck2', 's5', 's1', 'driver1'])\n",
      "33: ('disembarktruck', ['driver1', 'truck2', 's1'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_sequences(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Find classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d8471399c41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mactarg_tuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactarg_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "transitions = set() # A transition is denoted by action_name + argument position\n",
    "arguments = set()\n",
    "actions = set()\n",
    "for seq in sequences:\n",
    "    for actarg_tuple in seq:\n",
    "        actions.add(actarg_tuple[0])\n",
    "        for j, arg in enumerate(actarg_tuple[1]):\n",
    "            transitions.add(actarg_tuple[0]+\".\"+str(j))\n",
    "            arguments.add(arg)\n",
    "\n",
    "print(\"\\nActions\")\n",
    "print(actions)\n",
    "# print(\"\\nTransitions\")\n",
    "# print(transitions)\n",
    "print(\"\\nArguments/Objects\")\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actarg_dictionary(sequences):\n",
    "    d = defaultdict(list)\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            d[actarg_tuple[0]].append(actarg_tuple[1])\n",
    "    return d\n",
    "d = get_actarg_dictionary(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class util functions.\n",
    "def get_classes(d):\n",
    "    # TODO incorporate word similarity in get classes.\n",
    "    c = defaultdict(set)\n",
    "    for k,v in d.items():\n",
    "        for arg_list in v:\n",
    "            for i,object in enumerate(arg_list):\n",
    "                c[k,i].add(object)\n",
    "\n",
    "    sets = c.values()\n",
    "    classes = []\n",
    "    # remove duplicate classes\n",
    "    for s in sets:\n",
    "        if s not in classes:\n",
    "            classes.append(s)\n",
    "\n",
    "    # now do pairwise intersections of all values. If intersection, combine them; then return the final sets.\n",
    "    classes_copy = list(classes)\n",
    "    while True:\n",
    "        combinations = list(itertools.combinations(classes_copy,2))\n",
    "        intersections_count = 0\n",
    "        for combination in combinations:\n",
    "            if combination[0].intersection(combination[1]):\n",
    "                intersections_count +=1\n",
    "\n",
    "                if combination[0] in classes_copy:\n",
    "                    classes_copy.remove(combination[0])\n",
    "                if combination[1] in classes_copy:\n",
    "                    classes_copy.remove(combination[1])\n",
    "                classes_copy.append(combination[0].union(combination[1]))\n",
    "\n",
    "        if intersections_count==0:\n",
    "            # print(\"no intersections left\")\n",
    "            break\n",
    "\n",
    "    return classes_copy\n",
    "\n",
    "# TODO: Can use better approach here. NER might help.\n",
    "def get_class_names(classes):\n",
    "    # Name the class to first object found ignoring the digits in it\n",
    "    class_names = []\n",
    "    for c in classes:\n",
    "        for object in c:\n",
    "#             object = ''.join([i for i in object if not i.isdigit()])\n",
    "            class_names.append(object)\n",
    "            break\n",
    "    return class_names\n",
    "\n",
    "def get_class_index(arg,classes):\n",
    "    for class_index, c in enumerate(classes):\n",
    "        if arg in c:\n",
    "            return class_index #it is like breaking out of the loop\n",
    "    print(\"Error:class index not found\") #this statement is only executed if class index is not returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorts/Classes\n",
      "[{'driver2', 'driver1'}, {'truck1', 'truck2'}, {'package1', 'package4', 'package2', 'package5', 'package3'}, {'s1', 's0', 's5', 's3', 's4'}]\n",
      "\n",
      "Extracted class names\n",
      "['driver2', 'truck1', 'package1', 's1']\n"
     ]
    }
   ],
   "source": [
    "classes = get_classes(d) #sorts of object\n",
    "print(\"\\nSorts/Classes\")\n",
    "print(classes)\n",
    "\n",
    "class_names = get_class_names(classes)\n",
    "print(\"\\nExtracted class names\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT 1: Enter Correct Class names\n",
    "Editing the extracted class names to more readable object classes will make the final PDDL model more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renamed class names\n",
      "['driver', 'truck', 'package', 'location']\n"
     ]
    }
   ],
   "source": [
    "############ (Optional) User Input ############\n",
    "# Give user an option to change class names.\n",
    "# class_names[0] = 'rocket'\n",
    "\n",
    "#tyre\n",
    "# class_names[0] = 'Jack'\n",
    "# class_names[1] = 'Boot'\n",
    "# class_names[2] = 'Wheel'\n",
    "# class_names[3] = 'Hub'\n",
    "# class_names[4] = 'Wrench'\n",
    "# class_names[5] = 'Nut'\n",
    "\n",
    "#driverlog\n",
    "class_names[0] = 'Driver'\n",
    "class_names[1] = 'Truck'\n",
    "class_names[2] = 'Package'\n",
    "class_names[3] = 'Location'\n",
    "\n",
    "# #blocksworld\n",
    "# class_names[0] = 'Block'\n",
    "# class_names[1] = 'Gripper'\n",
    "\n",
    "\n",
    "print(\"\\nRenamed class names\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Assumptions of LOCM2**\n",
    "- Each object of a same class undergoes similar kind of transition.\n",
    "- Objects of same class in a same action undergo similar kind of transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actions\n",
      "{'loadtruck', 'drivetruck', 'unloadtruck', 'disembarktruck', 'boardtruck'}\n",
      "\n",
      "Transitions\n",
      "{'boardtruck.0', 'unloadtruck.0', 'unloadtruck.1', 'loadtruck.1', 'disembarktruck.0', 'disembarktruck.2', 'disembarktruck.1', 'loadtruck.0', 'drivetruck.0', 'drivetruck.2', 'drivetruck.3', 'drivetruck.1', 'boardtruck.1', 'boardtruck.2', 'loadtruck.2', 'unloadtruck.2'}\n",
      "{'drivetruck.truck.0', 'unloadtruck.package.0', 'loadtruck.truck.1', 'drivetruck.location.1', 'disembarktruck.location.2', 'boardtruck.truck.1', 'disembarktruck.driver.0', 'drivetruck.location.2', 'loadtruck.package.0', 'loadtruck.location.2', 'disembarktruck.truck.1', 'boardtruck.driver.0', 'drivetruck.driver.3', 'unloadtruck.location.2', 'unloadtruck.truck.1', 'boardtruck.location.2'}\n",
      "\n",
      "Arguments/Objects\n",
      "{'truck2', 'truck1', 'package1', 'package4', 'package2', 's3', 'package5', 's1', 's0', 'driver1', 's5', 'package3', 's4', 'driver2'}\n"
     ]
    }
   ],
   "source": [
    "# change transitions to be more meaningful by incorporating class_names.\n",
    "full_transitions = set()\n",
    "for seq in sequences:\n",
    "    for actarg_tuple in seq:\n",
    "        actions.add(actarg_tuple[0])\n",
    "        for j, arg in enumerate(actarg_tuple[1]):\n",
    "            full_transitions.add(actarg_tuple[0]+\".\"+class_names[get_class_index(arg,classes)]+'.'+str(j))\n",
    "            arguments.add(arg)\n",
    "\n",
    "print(\"\\nActions\")\n",
    "print(actions)\n",
    "print(\"\\nTransitions\")\n",
    "print(full_transitions)\n",
    "print(\"\\nArguments/Objects\")\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Actions: 5,\n",
      "Number of unique transitions: 16,\n",
      "Number of unique objects (arguments): 14,\n",
      "Number of classes/sorts: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of Actions: {},\\nNumber of unique transitions: {},\\nNumber of unique objects (arguments): {},\\nNumber of classes/sorts: {}\".format(len(actions), len(transitions), len(arguments), len(classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Transition graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def empty_directory(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            # elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))\n",
    "\n",
    "def print_table(matrix):\n",
    "    display(tabulate(matrix, headers='keys', tablefmt='html'))\n",
    "    \n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save graphs in graphml format (used in cytoscape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(graphs, domain_name):\n",
    "    adjacency_matrix_list = [] # list of adjacency matrices per class\n",
    "    \n",
    "    for index, G in enumerate(graphs):\n",
    "        nx.write_graphml(G, \"output/\"+ domain_name + \"/\" +  class_names[index] + \".graphml\")\n",
    "        df = nx.to_pandas_adjacency(G, nodelist=G.nodes(), dtype=int)\n",
    "        adjacency_matrix_list.append(df)\n",
    "#         print_table(df)\n",
    "    return adjacency_matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cytographs(graphs, domain_name, aml):\n",
    "    cytoscapeobs = []\n",
    "    for index, G in enumerate(graphs):\n",
    "            cytoscapeobj = CytoscapeWidget()\n",
    "            cytoscapeobj.graph.add_graph_from_networkx(G)\n",
    "            edge_list = list()\n",
    "            for source, target, data in G.edges(data=True):\n",
    "                edge_instance = Edge()\n",
    "                edge_instance.data['source'] = source\n",
    "                edge_instance.data['target'] = target\n",
    "                for k, v in data.items():\n",
    "                    cyto_attrs = ['group', 'removed', 'selected', 'selectable',\n",
    "                        'locked', 'grabbed', 'grabbable', 'classes', 'position', 'data']\n",
    "                    if k in cyto_attrs:\n",
    "                        setattr(edge_instance, k, v)\n",
    "                    else:\n",
    "                        edge_instance.data[k] = v\n",
    "                    edge_list.append(edge_instance)\n",
    "            cytoscapeobj.graph.edges = edge_list\n",
    "#             cytoscapeobj.graph.add_graph_from_df(aml[index],aml[index].columns.tolist())\n",
    "            cytoscapeobs.append(cytoscapeobj)\n",
    "#             print(cytoscapeobj)\n",
    "            printmd('## class **'+class_names[index]+'**')\n",
    "            print_table(aml[index])\n",
    "    #         print(\"Nodes:{}\".format(G.nodes()))\n",
    "    #         print(\"Edges:{}\".format(G.edges()))\n",
    "            cytoscapeobj.set_style([{\n",
    "                            'width':400,\n",
    "                            'height':400,\n",
    "\n",
    "                            'selector': 'node',\n",
    "                            'style': {\n",
    "                                'label': 'data(id)',\n",
    "                                'font-family': 'helvetica',\n",
    "                                'font-size': '8px',\n",
    "                                'background-color': '#11479e',\n",
    "                                'height':'10px',\n",
    "                                'width':'10px',\n",
    "\n",
    "\n",
    "                                }\n",
    "\n",
    "                            },\n",
    "                            {\n",
    "                            'selector': 'node:parent',\n",
    "                            'css': {\n",
    "                                'background-opacity': 0.333,\n",
    "                                'background-color': '#bbb'\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                            'selector': '$node > node',\n",
    "                            'css': {\n",
    "                                'padding-top': '10px',\n",
    "                                'padding-left': '10px',\n",
    "                                'padding-bottom': '10px',\n",
    "                                'padding-right': '10px',\n",
    "                                'text-valign': 'top',\n",
    "                                'text-halign': 'center',\n",
    "                                'background-color': '#bbb'\n",
    "                              }\n",
    "                            },\n",
    "                           {\n",
    "                                'selector': 'edge',\n",
    "\n",
    "                                'style': {\n",
    "                                    'label':'data(weight)',\n",
    "                                    'width': 1,\n",
    "                                    'line-color': '#9dbaea',\n",
    "                                    'target-arrow-shape': 'triangle',\n",
    "                                    'target-arrow-color': '#9dbaea',\n",
    "                                    'arrow-scale': 0.5,\n",
    "                                    'curve-style': 'bezier',\n",
    "                                    'font-family': 'helvetica',\n",
    "                                    'font-size': '8px',\n",
    "                                    'text-valign': 'top',\n",
    "                                    'text-halign':'center'\n",
    "                                }\n",
    "                            },\n",
    "                            ])\n",
    "            cytoscapeobj.max_zoom = 4.0\n",
    "            cytoscapeobj.min_zoom = 0.5\n",
    "            display(cytoscapeobj)\n",
    "    return cytoscapeobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build transitions graphs and call save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_transition_graphs(classes, domain_name, class_names):\n",
    "    # There should be a graph for each class of objects.\n",
    "    graphs = []\n",
    "    # Initialize all graphs empty\n",
    "    for sort in classes:\n",
    "        graphs.append(nx.DiGraph())\n",
    "\n",
    "    consecutive_transition_lists = [] #list of consecutive transitions per object instance per sequence.\n",
    "\n",
    "    for m, arg in enumerate(arguments):  # for all arguments (objects found in sequences)\n",
    "        for n, seq in enumerate(sequences):  # for all sequences\n",
    "            consecutive_transition_list = list()  # consecutive transition list for a sequence and an object (arg)\n",
    "            for i, actarg_tuple in enumerate(seq):\n",
    "                for j, arg_prime in enumerate(actarg_tuple[1]):  # for all arguments in actarg tuples\n",
    "                    if arg == arg_prime:  # if argument matches arg\n",
    "                        node = actarg_tuple[0] + \".\" +  str(j)\n",
    "                        # node = actarg_tuple[0] +  \".\" + class_names[get_class_index(arg,classes)] + \".\" +  str(j)  # name the node of graph which represents a transition\n",
    "                        consecutive_transition_list.append(node)  # add node to the cons_transition for sequence and argument\n",
    "\n",
    "                        # for each class append the nodes to the graph of that class\n",
    "                        class_index = get_class_index(arg_prime, classes)  # get index of class to which the object belongs to\n",
    "                        graphs[class_index].add_node(node)  # add node to the graph of that class\n",
    "\n",
    "            consecutive_transition_lists.append([n, arg, consecutive_transition_list])\n",
    "\n",
    "    # print(consecutive_transition_lists)\n",
    "    # for all consecutive transitions add edges to the appropriate graphs.\n",
    "    for cons_trans_list in consecutive_transition_lists:\n",
    "        # print(cons_trans_list)\n",
    "        seq_no = cons_trans_list[0]  # get sequence number\n",
    "        arg = cons_trans_list[1]  # get argument\n",
    "        class_index = get_class_index(arg, classes)  # get index of class\n",
    "        # add directed edges to graph of that class\n",
    "        for i in range(0, len(cons_trans_list[2]) - 1):\n",
    "                if graphs[class_index].has_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1]):\n",
    "                    graphs[class_index][cons_trans_list[2][i]][cons_trans_list[2][i + 1]]['weight'] += 1\n",
    "                else:\n",
    "                    graphs[class_index].add_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1], weight=1)\n",
    "\n",
    "\n",
    "    \n",
    "    # make directory if doesn't exist\n",
    "    dirName = \"output/\"+ domain_name\n",
    "    if not os.path.exists(dirName):\n",
    "        os.makedirs(dirName)\n",
    "        print(\"Directory \", dirName, \" Created \")\n",
    "    else:\n",
    "        print(\"Directory \", dirName, \" already exists\")\n",
    "    empty_directory(dirName)\n",
    "     \n",
    "    # save all the graphs\n",
    "    adjacency_matrix_list = save(graphs, domain_name) # list of adjacency matrices per class\n",
    "    \n",
    "    # plot cytoscape interactive graphs\n",
    "    cytoscapeobs = plot_cytographs(graphs,domain_name, adjacency_matrix_list)\n",
    "    \n",
    "    return adjacency_matrix_list, graphs, cytoscapeobsdef build_and_save_transition_graphs(classes, domain_name, class_names):\n",
    "    # There should be a graph for each class of objects.\n",
    "    graphs = []\n",
    "    # Initialize all graphs empty\n",
    "    for sort in classes:\n",
    "        graphs.append(nx.DiGraph())\n",
    "\n",
    "    consecutive_transition_lists = [] #list of consecutive transitions per object instance per sequence.\n",
    "\n",
    "    for m, arg in enumerate(arguments):  # for all arguments (objects found in sequences)\n",
    "        for n, seq in enumerate(sequences):  # for all sequences\n",
    "            consecutive_transition_list = list()  # consecutive transition list for a sequence and an object (arg)\n",
    "            for i, actarg_tuple in enumerate(seq):\n",
    "                for j, arg_prime in enumerate(actarg_tuple[1]):  # for all arguments in actarg tuples\n",
    "                    if arg == arg_prime:  # if argument matches arg\n",
    "                        node = actarg_tuple[0] + \".\" +  str(j)\n",
    "                        # node = actarg_tuple[0] +  \".\" + class_names[get_class_index(arg,classes)] + \".\" +  str(j)  # name the node of graph which represents a transition\n",
    "                        consecutive_transition_list.append(node)  # add node to the cons_transition for sequence and argument\n",
    "\n",
    "                        # for each class append the nodes to the graph of that class\n",
    "                        class_index = get_class_index(arg_prime, classes)  # get index of class to which the object belongs to\n",
    "                        graphs[class_index].add_node(node)  # add node to the graph of that class\n",
    "\n",
    "            consecutive_transition_lists.append([n, arg, consecutive_transition_list])\n",
    "\n",
    "    # print(consecutive_transition_lists)\n",
    "    # for all consecutive transitions add edges to the appropriate graphs.\n",
    "    for cons_trans_list in consecutive_transition_lists:\n",
    "        # print(cons_trans_list)\n",
    "        seq_no = cons_trans_list[0]  # get sequence number\n",
    "        arg = cons_trans_list[1]  # get argument\n",
    "        class_index = get_class_index(arg, classes)  # get index of class\n",
    "        # add directed edges to graph of that class\n",
    "        for i in range(0, len(cons_trans_list[2]) - 1):\n",
    "                if graphs[class_index].has_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1]):\n",
    "                    graphs[class_index][cons_trans_list[2][i]][cons_trans_list[2][i + 1]]['weight'] += 1\n",
    "                else:\n",
    "                    graphs[class_index].add_edge(cons_trans_list[2][i], cons_trans_list[2][i + 1], weight=1)\n",
    "\n",
    "\n",
    "    \n",
    "    # make directory if doesn't exist\n",
    "    dirName = \"output/\"+ domain_name\n",
    "    if not os.path.exists(dirName):\n",
    "        os.makedirs(dirName)\n",
    "        print(\"Directory \", dirName, \" Created \")\n",
    "    else:\n",
    "        print(\"Directory \", dirName, \" already exists\")\n",
    "    empty_directory(dirName)\n",
    "     \n",
    "    # save all the graphs\n",
    "    adjacency_matrix_list = save(graphs, domain_name) # list of adjacency matrices per class\n",
    "    \n",
    "    # plot cytoscape interactive graphs\n",
    "    cytoscapeobs = plot_cytographs(graphs,domain_name, adjacency_matrix_list)\n",
    "    \n",
    "    return adjacency_matrix_list, graphs, cytoscapeobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transition Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  output/driverlog  already exists\n",
      "driver\n",
      "Nodes:['boardtruck.0', 'drivetruck.3', 'disembarktruck.0']\n",
      "Edges:[('boardtruck.0', 'drivetruck.3'), ('drivetruck.3', 'drivetruck.3'), ('drivetruck.3', 'disembarktruck.0'), ('disembarktruck.0', 'boardtruck.0')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4637a90e4474876889460cd40d95261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 300, 'height': 300, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck\n",
      "Nodes:['boardtruck.1', 'loadtruck.1', 'drivetruck.0', 'unloadtruck.1', 'disembarktruck.1']\n",
      "Edges:[('boardtruck.1', 'loadtruck.1'), ('boardtruck.1', 'drivetruck.0'), ('loadtruck.1', 'drivetruck.0'), ('drivetruck.0', 'drivetruck.0'), ('drivetruck.0', 'unloadtruck.1'), ('drivetruck.0', 'disembarktruck.1'), ('drivetruck.0', 'loadtruck.1'), ('unloadtruck.1', 'drivetruck.0'), ('unloadtruck.1', 'disembarktruck.1'), ('disembarktruck.1', 'boardtruck.1')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ce7e37edfd4acda4137299b28514b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 300, 'height': 300, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package\n",
      "Nodes:['loadtruck.0', 'unloadtruck.0']\n",
      "Edges:[('loadtruck.0', 'unloadtruck.0')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3bac3f9b794a0e8e1ae4205ae70413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 300, 'height': 300, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "Nodes:['drivetruck.2', 'unloadtruck.2', 'drivetruck.1', 'disembarktruck.2', 'boardtruck.2', 'loadtruck.2']\n",
      "Edges:[('drivetruck.2', 'unloadtruck.2'), ('drivetruck.2', 'drivetruck.1'), ('drivetruck.2', 'disembarktruck.2'), ('drivetruck.2', 'loadtruck.2'), ('unloadtruck.2', 'drivetruck.1'), ('unloadtruck.2', 'disembarktruck.2'), ('drivetruck.1', 'drivetruck.2'), ('drivetruck.1', 'boardtruck.2'), ('disembarktruck.2', 'drivetruck.2'), ('disembarktruck.2', 'boardtruck.2'), ('boardtruck.2', 'loadtruck.2'), ('boardtruck.2', 'drivetruck.1'), ('loadtruck.2', 'drivetruck.1')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec1da08768741b1baf00eb2918e80bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'width': 300, 'height': 300, 'selector': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Build weighted directed graphs for transitions.\n",
    "printmd(\"## \"+ domain_name.upper())\n",
    "adjacency_matrix_list, graphs, cytoscapeobjs = build_and_save_transition_graphs(classes, domain_name, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT 2: Edit transition graphs\n",
    "For meaningful LOCM models, here one can edit the transition graphs to make them accurate. However, in the paper we don't do that in order to estimate what kind of models are learned automatically from natural language data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1. **You can add or delete nodes/edges in transition graphs by following methods like add_node, delete_edges shown in the following library.**\n",
    "https://github.com/QuantStack/ipycytoscape/blob/master/ipycytoscape/cytoscape.py\n",
    "\n",
    "Option 2. **Alternatively you can use the saved .graphml file. Open it up in Cytoscape, edit it within the GUI and load that graph into the graphs list.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get Transition Sets from LOCM2\n",
    "\n",
    "**Algorithm**: LOCM2\n",
    "\n",
    "**Input** : \n",
    "- T_all = set of observed transitions for a sort/class\n",
    "- H : Set of holes - each hole is a set of two transitions.\n",
    "- P : Set of pairs <t1,t2> i.e. consecutive transitions.\n",
    "- E : Set of example sequences of actions.\n",
    "\n",
    "**Output**:\n",
    "- S : Set of transition sets.\n",
    "### Finding holes\n",
    "Holes are transitions that LOCM1 will assume to be true due to the flaw of overgeneralizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix_list_with_holes = get_adjacency_matrix_with_holes(adjacency_matrix_list)\n",
    "\n",
    "# Printing FSM matrices with and without holes\n",
    "for index,adjacency_matrix in enumerate(adjacency_matrix_list):\n",
    "    printmd(\"\\n#### \" + class_names[index] )\n",
    "    print_table(adjacency_matrix)\n",
    "\n",
    "    printmd(\"\\n#### HOLES: \" + class_names[index])\n",
    "    print_table(adjacency_matrix_list_with_holes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========driver==========\n",
      "                  boardtruck.0  drivetruck.3  disembarktruck.0\n",
      "boardtruck.0                 0             5                 0\n",
      "drivetruck.3                 0             9                 5\n",
      "disembarktruck.0             3             0                 0\n",
      "|                  |   boardtruck.0 |   drivetruck.3 |   disembarktruck.0 |\n",
      "|------------------|----------------|----------------|--------------------|\n",
      "| boardtruck.0     |              0 |              5 |                  0 |\n",
      "| drivetruck.3     |              0 |              9 |                  5 |\n",
      "| disembarktruck.0 |              3 |              0 |                  0 |\n",
      "\n",
      "===== HOLES: driver==========\n",
      "|                  |   boardtruck.0 |   drivetruck.3 | disembarktruck.0   |\n",
      "|------------------|----------------|----------------|--------------------|\n",
      "| boardtruck.0     |              0 |              5 | hole               |\n",
      "| drivetruck.3     |              0 |              9 | 5                  |\n",
      "| disembarktruck.0 |              3 |              0 | 0                  |\n",
      "\n",
      "==========truck==========\n",
      "                  boardtruck.1  loadtruck.1  drivetruck.0  unloadtruck.1  \\\n",
      "boardtruck.1                 0            3             2              0   \n",
      "loadtruck.1                  0            0             5              0   \n",
      "drivetruck.0                 0            2             3              5   \n",
      "unloadtruck.1                0            0             4              0   \n",
      "disembarktruck.1             3            0             0              0   \n",
      "\n",
      "                  disembarktruck.1  \n",
      "boardtruck.1                     0  \n",
      "loadtruck.1                      0  \n",
      "drivetruck.0                     4  \n",
      "unloadtruck.1                    1  \n",
      "disembarktruck.1                 0  \n",
      "|                  |   boardtruck.1 |   loadtruck.1 |   drivetruck.0 |   unloadtruck.1 |   disembarktruck.1 |\n",
      "|------------------|----------------|---------------|----------------|-----------------|--------------------|\n",
      "| boardtruck.1     |              0 |             3 |              2 |               0 |                  0 |\n",
      "| loadtruck.1      |              0 |             0 |              5 |               0 |                  0 |\n",
      "| drivetruck.0     |              0 |             2 |              3 |               5 |                  4 |\n",
      "| unloadtruck.1    |              0 |             0 |              4 |               0 |                  1 |\n",
      "| disembarktruck.1 |              3 |             0 |              0 |               0 |                  0 |\n",
      "\n",
      "===== HOLES: truck==========\n",
      "|                  |   boardtruck.1 | loadtruck.1   |   drivetruck.0 | unloadtruck.1   | disembarktruck.1   |\n",
      "|------------------|----------------|---------------|----------------|-----------------|--------------------|\n",
      "| boardtruck.1     |              0 | 3             |              2 | hole            | hole               |\n",
      "| loadtruck.1      |              0 | hole          |              5 | hole            | hole               |\n",
      "| drivetruck.0     |              0 | 2             |              3 | 5               | 4                  |\n",
      "| unloadtruck.1    |              0 | hole          |              4 | hole            | 1                  |\n",
      "| disembarktruck.1 |              3 | 0             |              0 | 0               | 0                  |\n",
      "\n",
      "==========package==========\n",
      "               loadtruck.0  unloadtruck.0\n",
      "loadtruck.0              0              5\n",
      "unloadtruck.0            0              0\n",
      "|               |   loadtruck.0 |   unloadtruck.0 |\n",
      "|---------------|---------------|-----------------|\n",
      "| loadtruck.0   |             0 |               5 |\n",
      "| unloadtruck.0 |             0 |               0 |\n",
      "\n",
      "===== HOLES: package==========\n",
      "|               |   loadtruck.0 |   unloadtruck.0 |\n",
      "|---------------|---------------|-----------------|\n",
      "| loadtruck.0   |             0 |               5 |\n",
      "| unloadtruck.0 |             0 |               0 |\n",
      "\n",
      "==========location==========\n",
      "                  drivetruck.2  unloadtruck.2  drivetruck.1  disembarktruck.2  \\\n",
      "drivetruck.2                 0              5             3                 4   \n",
      "unloadtruck.2                0              0             4                 1   \n",
      "drivetruck.1                10              0             0                 0   \n",
      "disembarktruck.2             1              0             0                 0   \n",
      "boardtruck.2                 0              0             2                 0   \n",
      "loadtruck.2                  0              0             5                 0   \n",
      "\n",
      "                  boardtruck.2  loadtruck.2  \n",
      "drivetruck.2                 0            2  \n",
      "unloadtruck.2                0            0  \n",
      "drivetruck.1                 1            0  \n",
      "disembarktruck.2             2            0  \n",
      "boardtruck.2                 0            3  \n",
      "loadtruck.2                  0            0  \n",
      "|                  |   drivetruck.2 |   unloadtruck.2 |   drivetruck.1 |   disembarktruck.2 |   boardtruck.2 |   loadtruck.2 |\n",
      "|------------------|----------------|-----------------|----------------|--------------------|----------------|---------------|\n",
      "| drivetruck.2     |              0 |               5 |              3 |                  4 |              0 |             2 |\n",
      "| unloadtruck.2    |              0 |               0 |              4 |                  1 |              0 |             0 |\n",
      "| drivetruck.1     |             10 |               0 |              0 |                  0 |              1 |             0 |\n",
      "| disembarktruck.2 |              1 |               0 |              0 |                  0 |              2 |             0 |\n",
      "| boardtruck.2     |              0 |               0 |              2 |                  0 |              0 |             3 |\n",
      "| loadtruck.2      |              0 |               0 |              5 |                  0 |              0 |             0 |\n",
      "\n",
      "===== HOLES: location==========\n",
      "|                  |   drivetruck.2 | unloadtruck.2   |   drivetruck.1 | disembarktruck.2   |   boardtruck.2 | loadtruck.2   |\n",
      "|------------------|----------------|-----------------|----------------|--------------------|----------------|---------------|\n",
      "| drivetruck.2     |              0 | 5               |              3 | 4                  |              0 | 2             |\n",
      "| unloadtruck.2    |              0 | hole            |              4 | 1                  |              0 | hole          |\n",
      "| drivetruck.1     |             10 | 0               |              0 | 0                  |              1 | 0             |\n",
      "| disembarktruck.2 |              1 | 0               |              0 | 0                  |              2 | 0             |\n",
      "| boardtruck.2     |              0 | hole            |              2 | hole               |              0 | 3             |\n",
      "| loadtruck.2      |              0 | hole            |              5 | hole               |              0 | hole          |\n"
     ]
    }
   ],
   "source": [
    "adjacency_matrix_list_with_holes = get_adjacency_matrix_with_holes(adjacency_matrix_list)\n",
    "\n",
    "# Printing FSM matrices with and without holes\n",
    "for index,adjacency_matrix in enumerate(adjacency_matrix_list):\n",
    "    print(\"\\n==========\" + class_names[index] + \"==========\")\n",
    "    print(adjacency_matrix)\n",
    "    print(tabulate(adjacency_matrix, headers='keys', tablefmt='github'))\n",
    "\n",
    "    print(\"\\n===== HOLES: \" + class_names[index] + \"==========\")\n",
    "    print(tabulate(adjacency_matrix_list_with_holes[index], headers='keys', tablefmt='github'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of set of holes per class (H)\n",
    "holes_per_class = []\n",
    "\n",
    "for index,df in enumerate(adjacency_matrix_list_with_holes):\n",
    "    holes = set()\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[1]):\n",
    "            if df.iloc[i,j] == 'hole':\n",
    "                holes.add(frozenset({df.index[i] , df.columns[j]}))\n",
    "    holes_per_class.append(holes)\n",
    "for i, hole in enumerate(holes_per_class):\n",
    "    print(\"#holes in class \" + class_names[i]+\":\" + str(len(hole)))\n",
    "#     for h in hole:\n",
    "#         print(list(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T_all - Set of observed transitions for a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver:['boardtruck.0' 'drivetruck.3' 'disembarktruck.0']\n",
      "truck:['boardtruck.1' 'loadtruck.1' 'drivetruck.0' 'unloadtruck.1'\n",
      " 'disembarktruck.1']\n",
      "package:['loadtruck.0' 'unloadtruck.0']\n",
      "location:['drivetruck.2' 'unloadtruck.2' 'drivetruck.1' 'disembarktruck.2'\n",
      " 'boardtruck.2' 'loadtruck.2']\n"
     ]
    }
   ],
   "source": [
    "# List of transitions per class (T_all). It is just a set of transitions that occur for a class.\n",
    "transitions_per_class = []\n",
    "for index, df in enumerate(adjacency_matrix_list_with_holes):\n",
    "    transitions_per_class.append(df.columns.values)\n",
    "# for i, transition in enumerate(transitions_per_class):\n",
    "#     print('{}:{}'.format(class_names[i], transition))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P - set of pairs <t1,t2> (consecutive transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consecutive_transitions_per_class(adjacency_matrix_list_with_holes):\n",
    "    consecutive_transitions_per_class = []\n",
    "    for index, df in enumerate(adjacency_matrix_list_with_holes):\n",
    "        consecutive_transitions = set()  # for a class\n",
    "        for i in range(df.shape[0]):\n",
    "            for j in range(df.shape[1]):\n",
    "                if df.iloc[i, j] != 'hole':\n",
    "                    if df.iloc[i, j] > 0:\n",
    "#                         print(\"(\" + df.index[i] + \",\" + df.columns[j] + \")\")\n",
    "                        consecutive_transitions.add((df.index[i], df.columns[j]))\n",
    "        consecutive_transitions_per_class.append(consecutive_transitions)\n",
    "    return consecutive_transitions_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create list of consecutive transitions per class (P). If value is not null, ordered pair i,j would be consecutive transitions per class\n",
    "consecutive_transitions_per_class = get_consecutive_transitions_per_class(adjacency_matrix_list_with_holes)\n",
    "# printmd(\"###  Consecutive transitions per class\")\n",
    "# for i, transition in enumerate(consecutive_transitions_per_class):\n",
    "#     printmd(\"#### \"+class_names[i]+\":\")\n",
    "#     for x in list(transition):\n",
    "#         print(x)\n",
    "# #     print('{}:{}'.format(class_names[i], transition))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Well Formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Getting transitions sets for each class using LOCM2 ######\n"
     ]
    }
   ],
   "source": [
    "def check_well_formed(subset_df):\n",
    "    # got the adjacency matrix subset\n",
    "    df = subset_df.copy()\n",
    "    well_formed_flag = True\n",
    "    \n",
    "    \n",
    "    if (df == 0).all(axis=None): # all elements are zero\n",
    "        well_formed_flag = False\n",
    "        \n",
    "    # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "    for i in range(0, df.shape[0]-1):\n",
    "        for j in range(i + 1, df.shape[0]):\n",
    "            print(i,j)\n",
    "            idx1, idx2 = i, j\n",
    "            row1, row2 = df.iloc[idx1, :], df.iloc[idx2, :]  # we have now all pairs of rows\n",
    "\n",
    "            common_values_flag = False  # for each two rows we have a common_values_flag\n",
    "\n",
    "            # if there is a common value between two rows, turn common value flag to true\n",
    "            for col in range(row1.shape[0]):\n",
    "                if row1.iloc[col] > 0 and row2.iloc[col] > 0:\n",
    "                    common_values_flag = True\n",
    "                    break\n",
    "          \n",
    "            if common_values_flag:\n",
    "                for col in range(row1.shape[0]): # check for holes if common value\n",
    "                    if row1.iloc[col] > 0 and row2.iloc[col] == 0:\n",
    "                        well_formed_flag = False\n",
    "                    elif row1.iloc[col] == 0 and row2.iloc[col] > 0:\n",
    "                        well_formed_flag = False\n",
    "    \n",
    "    if not well_formed_flag:\n",
    "        return False\n",
    "    elif well_formed_flag:\n",
    "        return True\n",
    "     \n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Valid Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid(subset_df,consecutive_transitions_per_class):\n",
    "    \n",
    "    # Note: Essentially we check validity against P instead of E. \n",
    "    # In the paper of LOCM2, it isn't mentioned how to check against E.\n",
    "    \n",
    "    # Reasoning: If we check against all consecutive transitions per class, \n",
    "    # we essentially check against all example sequences.\n",
    "    # check the candidate set which is well-formed (subset df against all consecutive transitions)\n",
    "\n",
    "    # got the adjacency matrix subset\n",
    "    df = subset_df.copy()\n",
    "\n",
    "    # for particular adjacency matrix's copy, loop over all pairs of rows\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(df.shape[0]):\n",
    "            if df.iloc[i,j] > 0:\n",
    "                valid_val_flag = False\n",
    "                ordered_pair = (df.index[i], df.columns[j])\n",
    "                for ct_list in consecutive_transitions_per_class:\n",
    "                    for ct in ct_list:\n",
    "                        if ordered_pair == ct:\n",
    "                            valid_val_flag=True\n",
    "                # if after all iteration ordered pair is not found, mark the subset as invalid.\n",
    "                if not valid_val_flag:\n",
    "                    return False\n",
    "                \n",
    "    # return True if all ordered pairs found.\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOCM2 transition sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locm2_get_transition_sets_per_class(holes_per_class, transitions_per_class, consecutive_transitions_per_class):\n",
    "    \"\"\"LOCM 2 Algorithm in the original LOCM2 paper\"\"\"\n",
    "    \n",
    "    # contains Solution Set S for each class.\n",
    "    transition_sets_per_class = []\n",
    "\n",
    "    # for each hole for a class/sort\n",
    "    for index, holes in enumerate(holes_per_class):\n",
    "        class_name = class_names[index]\n",
    "        printmd(\"### \"+  class_name)\n",
    "        \n",
    "        # S\n",
    "        transition_set_list = [] #transition_sets_of_a_class, # intially it's empty\n",
    "        \n",
    "        if len(holes)==0:\n",
    "            print(\"no holes\") # S will contain just T_all\n",
    "        \n",
    "        if len(holes) > 0: # if there are any holes for a class\n",
    "            print(str(len(holes)) + \" holes\")\n",
    "            for ind, hole in enumerate(holes):\n",
    "                printmd(\"#### Hole \" + str(ind + 1) + \": \" + str(set(hole)))\n",
    "                is_hole_already_covered_flag = False\n",
    "                if len(transition_set_list)>0:\n",
    "                    for s_prime in transition_set_list:\n",
    "                        if hole.issubset(s_prime):\n",
    "                            printmd(\"Hole \"+ str(set(hole)) + \" is already covered.\")\n",
    "                            is_hole_already_covered_flag = True\n",
    "                            break\n",
    "                     \n",
    "                # discover a set which includes hole and is well-formed and valid against test data.\n",
    "                # if hole is not covered, do BFS with sets of increasing sizes starting with s=hole\n",
    "                if not is_hole_already_covered_flag: \n",
    "                    h = hole.copy()\n",
    "                    candidate_sets = []\n",
    "                    # all subsets of T_all starting from hole's len +1 to T_all-1.\n",
    "                    for i in range(len(h)+1,len(transitions_per_class[index])): \n",
    "                        subsets = findsubsets(transitions_per_class[index],i) # all subsets of length i\n",
    "\n",
    "                        for s in subsets:\n",
    "                            if h.issubset(s): # if  is subset of s\n",
    "                                candidate_sets.append(set(s))\n",
    "                        \n",
    "                        s_well_formed_and_valid = False\n",
    "                        for s in candidate_sets:\n",
    "                            if len(s)>=i:\n",
    "                                printmd(\"Checking candidate set *\" + str(s) + \"* of class **\" + class_name + \"** for well formedness and Validity\")\n",
    "                                subset_df = adjacency_matrix_list[index].loc[list(s),list(s)]\n",
    "                                print_table(subset_df)\n",
    "\n",
    "                                # checking for well-formedness\n",
    "                                well_formed_flag = False\n",
    "                                well_formed_flag = check_well_formed(subset_df)\n",
    "                                if not well_formed_flag:\n",
    "                                    print(\"This subset is NOT well-formed\")\n",
    "                                    \n",
    "                                elif well_formed_flag:\n",
    "                                    print(\"This subset is well-formed.\")\n",
    "                                    # if well-formed validate across the data E\n",
    "                                    # to remove inappropriate dead-ends\n",
    "                                    valid_against_data_flag = False\n",
    "                                    valid_against_data_flag = check_valid(subset_df, consecutive_transitions_per_class)\n",
    "                                    if not valid_against_data_flag:\n",
    "                                        print(\"This subset is well-formed but invalid against example data\")\n",
    "\n",
    "                                    if valid_against_data_flag:\n",
    "                                        print(\"This subset is valid.\")\n",
    "                                        print(\"Adding this subset \" + str(s) +\" to the locm2 transition set.\")\n",
    "                                        if s not in transition_set_list: # do not allow copies.\n",
    "                                            transition_set_list.append(s)\n",
    "                                        \n",
    "                                        print(\"Hole that is covered now:\")\n",
    "                                        print(list(h))\n",
    "                                        s_well_formed_and_valid = True\n",
    "                                        break \n",
    "                        if s_well_formed_and_valid:\n",
    "                                break\n",
    "                                        \n",
    "                                        \n",
    "\n",
    "        print(transition_set_list)                                    \n",
    "        #step 7 : remove redundant sets S - {s1}\n",
    "        ts_copy = transition_set_list.copy()\n",
    "        for i in range(len(ts_copy)):\n",
    "            for j in range(len(ts_copy)):\n",
    "                if ts_copy[i] < ts_copy[j]: #if subset\n",
    "                    if ts_copy[i] in transition_set_list:\n",
    "                        transition_set_list.remove(ts_copy[i])\n",
    "                elif ts_copy[i] > ts_copy[j]:\n",
    "                    if ts_copy[j] in transition_set_list:\n",
    "                        transition_set_list.remove(ts_copy[j])\n",
    "        print(\"\\nRemoved redundancy transition set list\")\n",
    "        print(transition_set_list)\n",
    "\n",
    "        #step-8: include all-transitions machine, even if it is not well-formed.\n",
    "        transition_set_list.append(set(transitions_per_class[index])) #fallback\n",
    "        printmd(\"#### Final transition set list\")\n",
    "        print(transition_set_list)\n",
    "        transition_sets_per_class.append(transition_set_list)\n",
    "        \n",
    "\n",
    "    return transition_sets_per_class\n",
    "\n",
    "\n",
    "############    LOCM2 #################\n",
    "####    Input ready for LOCM2, Starting LOCM2 algorithm now\n",
    "####    Step 8:  selecting transition sets (TS) [Main LOCM2 Algorithm]\n",
    "printmd(\"### Getting transitions sets for each class using LOCM2\")\n",
    "transition_sets_per_class = locm2_get_transition_sets_per_class(holes_per_class, transitions_per_class, consecutive_transitions_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Algorithm For Induction of State Machines\n",
    "\n",
    "- Input: Action training sequence of length N\n",
    "- Output: Transition Set TS, Object states OS.\n",
    "\n",
    "We already have transition set TS per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cytographs_fsm(graph, domain_name):\n",
    "    cytoscapeobj = CytoscapeWidget()\n",
    "    cytoscapeobj.graph.add_graph_from_networkx(graph)\n",
    "    edge_list = list()\n",
    "    for source, target, data in graph.edges(data=True):\n",
    "        edge_instance = Edge()\n",
    "        edge_instance.data['source'] = source\n",
    "        edge_instance.data['target'] = target\n",
    "        for k, v in data.items():\n",
    "            cyto_attrs = ['group', 'removed', 'selected', 'selectable',\n",
    "                'locked', 'grabbed', 'grabbable', 'classes', 'position', 'data']\n",
    "            if k in cyto_attrs:\n",
    "                setattr(edge_instance, k, v)\n",
    "            else:\n",
    "                edge_instance.data[k] = v\n",
    "            edge_list.append(edge_instance)\n",
    "\n",
    "    cytoscapeobj.graph.edges = edge_list\n",
    "#     print(\"Nodes:{}\".format(graph.nodes()))\n",
    "#     print(\"Edges:{}\".format(graph.edges()))\n",
    "    cytoscapeobj.set_style([{\n",
    "                    'width':400,\n",
    "                    'height':500,\n",
    "\n",
    "                    'selector': 'node',\n",
    "                    'style': {\n",
    "                        'label': 'data(id)',\n",
    "                        'font-family': 'helvetica',\n",
    "                        'font-size': '8px',\n",
    "                        'background-color': '#11479e',\n",
    "                        'height':'10px',\n",
    "                        'width':'10px',\n",
    "\n",
    "\n",
    "                        }\n",
    "\n",
    "                    },\n",
    "                    {\n",
    "                    'selector': 'node:parent',\n",
    "                    'css': {\n",
    "                        'background-opacity': 0.333,\n",
    "                        'background-color': '#bbb'\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                    'selector': '$node > node',\n",
    "                    'css': {\n",
    "                        'padding-top': '10px',\n",
    "                        'padding-left': '10px',\n",
    "                        'padding-bottom': '10px',\n",
    "                        'padding-right': '10px',\n",
    "                        'text-valign': 'top',\n",
    "                        'text-halign': 'center',\n",
    "                        'background-color': '#bbb'\n",
    "                      }\n",
    "                    },\n",
    "                   {\n",
    "                        'selector': 'edge',\n",
    "\n",
    "                        'style': {\n",
    "                            'label':'data(weight)',\n",
    "                            'width': 1,\n",
    "                            'line-color': '#9dbaea',\n",
    "                            'target-arrow-shape': 'triangle',\n",
    "                            'target-arrow-color': '#9dbaea',\n",
    "                            'arrow-scale': 0.5,\n",
    "                            'curve-style': 'bezier',\n",
    "                            'font-family': 'helvetica',\n",
    "                            'font-size': '8px',\n",
    "                            'text-valign': 'top',\n",
    "                            'text-halign':'center'\n",
    "                        }\n",
    "                    },\n",
    "                    ])\n",
    "    cytoscapeobj.max_zoom = 2.0\n",
    "    cytoscapeobj.min_zoom = 0.5\n",
    "    display(cytoscapeobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First make start(t) and end(t) as state for each transition in FSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_machines_overall_list = []\n",
    "\n",
    "for index, ts_class in enumerate(transition_sets_per_class):\n",
    "    fsms_per_class = []\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    num_fsms = len(ts_class)\n",
    "    print(\"Number of FSMS:\" + str(num_fsms))\n",
    "    \n",
    "    for fsm_no, ts in enumerate(ts_class):\n",
    "        fsm_graph = nx.DiGraph()\n",
    "        \n",
    "        printmd(\"#### FSM \" + str(fsm_no))\n",
    "        for t in ts:\n",
    "            source = \"s(\" + str(t) + \")\"\n",
    "            target = \"e(\" + str(t) + \")\"\n",
    "            fsm_graph.add_edge(source,target,weight=t)\n",
    "        \n",
    "       \n",
    "        t_df = adjacency_matrix_list[index].loc[list(ts), list(ts)] #transition df for this fsm\n",
    "        print_table(t_df)\n",
    "        \n",
    "        \n",
    "        # merge end(t1) = start(t2) from transition df\n",
    "        \n",
    "        edge_t_list = [] # edge transition list\n",
    "        for i in range(t_df.shape[0]):\n",
    "            for j in range(t_df.shape[1]):\n",
    "                \n",
    "                if t_df.iloc[i, j] != 'hole':\n",
    "                    if t_df.iloc[i, j] > 0:\n",
    "                        for node in fsm_graph.nodes():\n",
    "                            if \"e(\"+t_df.index[i]+\")\" in node:\n",
    "                                merge_node1 = node\n",
    "                            if \"s(\"+t_df.index[j]+\")\" in node:\n",
    "                                merge_node2 = node\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "\n",
    "                        fsm_graph = nx.contracted_nodes(fsm_graph, merge_node1, merge_node2 , self_loops=True)\n",
    "\n",
    "                        if merge_node1 != merge_node2:\n",
    "                            mapping = {merge_node1: merge_node1 + \"|\" + merge_node2} \n",
    "                            fsm_graph = nx.relabel_nodes(fsm_graph, mapping)\n",
    "\n",
    "        # we need to complete the list of transitions \n",
    "        # that can happen on self-loop nodes \n",
    "        # as these have been overwritten (as graph is not MultiDiGraph)\n",
    "        \n",
    "        sl_state_list = list(nx.nodes_with_selfloops(fsm_graph)) # self looping states.\n",
    "        # if state is self-looping\n",
    "        t_list = []\n",
    "        if len(sl_state_list)>0: \n",
    "            # if s(T1) and e(T1) are there for same node, this T1 can self-loop occur.\n",
    "            for s in sl_state_list:\n",
    "                for sub_s in s.split('|'):\n",
    "                    if sub_s[0] == 'e':\n",
    "                        if ('s' + sub_s[1:]) in s.split('|'):\n",
    "                            t_list.append(sub_s[2:-1])\n",
    "                fsm_graph[s][s]['weight'] = '|'.join(t_list)\n",
    "        \n",
    "        \n",
    "\n",
    "               \n",
    "        plot_cytographs_fsm(fsm_graph,domain_name)\n",
    "        df = nx.to_pandas_adjacency(fsm_graph, nodelist=fsm_graph.nodes(), weight = 1)\n",
    "        print_table(df)\n",
    "        fsms_per_class.append(fsm_graph)\n",
    "    state_machines_overall_list.append(fsms_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## USER INPUT 3: Rename States. \n",
    "\n",
    "\n",
    "As states are shown in terms of end and start of transitions, user can rename them for easy readability later on.\n",
    "\n",
    "If states are renamed, certain hardcoded aspects of code won't work. It is advisable to create a  separate state dictionary and use it after step 9: (formation of PDDL model) to replace states in PDDL code.\n",
    "\n",
    "\n",
    "This also makes it easier to specify problem statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic creation: rename states as integers 0, 1, 2 .. etc. for each fsm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An Automatic state dictionary is added here where states are \n",
    "# renamed as 0, 1, 2 etc. for a specific FSM\n",
    "\n",
    "state_mappings_class = []\n",
    "state_machines_overall_list_2 = []\n",
    "for index, fsm_graphs in enumerate(state_machines_overall_list):\n",
    "    state_mappings_fsm = []\n",
    "    fsms_per_class_2 = []\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    num_fsms = len(fsm_graphs)\n",
    "    print(\"Number of FSMS:\" + str(num_fsms))\n",
    "    \n",
    "    for fsm_no, G in enumerate(fsm_graphs):\n",
    "        \n",
    "        state_mapping = {k: v for v, k in enumerate(G.nodes())}\n",
    "        G_copy = nx.relabel_nodes(G, state_mapping)\n",
    "        \n",
    "        plot_cytographs_fsm(G, domain_name)\n",
    "        plot_cytographs_fsm(G_copy, domain_name)\n",
    "        printmd(\"Fsm \"+ str(fsm_no))\n",
    "        fsms_per_class_2.append(G_copy)\n",
    "        state_mappings_fsm.append(state_mapping)\n",
    "        \n",
    "    state_machines_overall_list_2.append(fsms_per_class_2)\n",
    "    state_mappings_class.append(state_mappings_fsm)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the graph, User can specify states here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User can specify states here.\n",
    "# assign your states in state dictionary called state_mapping\n",
    "# e.g. state_mapping['e(removewheek.2)|s(putonwheel.2)'] = 'jack_free_to_use'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Induction of parameterized state machines\n",
    "Create and test hypothesis for state parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Form Hyp for HS (Hypothesis set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n",
      "Step 5: Induction of Parameterised Finite State Machines\n",
      "CLASS:driver\n",
      "FSM:1\n",
      "|        |   state0 |   state1 |\n",
      "|--------|----------|----------|\n",
      "| state0 |       19 |        0 |\n",
      "| state1 |        0 |        3 |\n",
      "\n",
      "Transition set of this class:\n",
      "[{'boardtruck.0', 'disembarktruck.0', 'drivetruck.3'}]\n",
      "CLASS:truck\n",
      "FSM:1\n",
      "|        |   state0 |   state1 |   state2 |   state3 |   state4 |\n",
      "|--------|----------|----------|----------|----------|----------|\n",
      "| state0 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state1 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state2 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state3 |        0 |        0 |        0 |        3 |        0 |\n",
      "| state4 |        0 |        0 |        0 |        0 |        0 |\n",
      "FSM:2\n",
      "|        |   state0 |   state1 |   state2 |   state3 |\n",
      "|--------|----------|----------|----------|----------|\n",
      "| state0 |        0 |        0 |        0 |        0 |\n",
      "| state1 |        0 |        0 |        0 |        0 |\n",
      "| state2 |        0 |        0 |        3 |        0 |\n",
      "| state3 |        0 |        0 |        0 |        1 |\n",
      "FSM:3\n",
      "|        |   state0 |   state1 |   state2 |   state3 |   state4 |\n",
      "|--------|----------|----------|----------|----------|----------|\n",
      "| state0 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state1 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state2 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state3 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state4 |        0 |        0 |        0 |        0 |        1 |\n",
      "FSM:4\n",
      "|        |   state0 |   state1 |\n",
      "|--------|----------|----------|\n",
      "| state0 |        3 |        0 |\n",
      "| state1 |        0 |       29 |\n",
      "\n",
      "Transition set of this class:\n",
      "[{'boardtruck.1', 'unloadtruck.1', 'loadtruck.1'}, {'boardtruck.1', 'unloadtruck.1', 'disembarktruck.1'}, {'disembarktruck.1', 'unloadtruck.1', 'loadtruck.1'}, {'unloadtruck.1', 'loadtruck.1', 'disembarktruck.1', 'drivetruck.0', 'boardtruck.1'}]\n",
      "CLASS:package\n",
      "FSM:1\n",
      "|        |   state0 |   state1 |   state2 |\n",
      "|--------|----------|----------|----------|\n",
      "| state0 |        0 |        0 |        0 |\n",
      "| state1 |        0 |        5 |        0 |\n",
      "| state2 |        0 |        0 |        0 |\n",
      "\n",
      "Transition set of this class:\n",
      "[{'unloadtruck.0', 'loadtruck.0'}]\n",
      "CLASS:location\n",
      "FSM:1\n",
      "|        |   state0 |   state1 |   state2 |   state3 |\n",
      "|--------|----------|----------|----------|----------|\n",
      "| state0 |        0 |        0 |        0 |        0 |\n",
      "| state1 |        0 |        0 |        0 |        0 |\n",
      "| state2 |        0 |        0 |        0 |        0 |\n",
      "| state3 |        0 |        0 |        0 |        9 |\n",
      "FSM:2\n",
      "|        |   state0 |   state1 |   state2 |\n",
      "|--------|----------|----------|----------|\n",
      "| state0 |        3 |        0 |        0 |\n",
      "| state1 |        0 |        0 |        0 |\n",
      "| state2 |        0 |        0 |        4 |\n",
      "FSM:3\n",
      "|        |   state0 |   state1 |   state2 |   state3 |   state4 |\n",
      "|--------|----------|----------|----------|----------|----------|\n",
      "| state0 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state1 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state2 |        0 |        0 |        1 |        0 |        0 |\n",
      "| state3 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state4 |        0 |        0 |        0 |        0 |        0 |\n",
      "FSM:4\n",
      "|        |   state0 |   state1 |   state2 |   state3 |   state4 |\n",
      "|--------|----------|----------|----------|----------|----------|\n",
      "| state0 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state1 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state2 |        0 |        0 |        0 |        0 |        0 |\n",
      "| state3 |        0 |        0 |        0 |        3 |        0 |\n",
      "| state4 |        0 |        0 |        0 |        0 |        0 |\n",
      "FSM:5\n",
      "|        |   state0 |   state1 |\n",
      "|--------|----------|----------|\n",
      "| state0 |       29 |        0 |\n",
      "| state1 |        0 |       14 |\n",
      "\n",
      "Transition set of this class:\n",
      "[{'loadtruck.2', 'unloadtruck.2', 'drivetruck.1'}, {'boardtruck.2', 'drivetruck.2', 'disembarktruck.2'}, {'loadtruck.2', 'unloadtruck.2', 'disembarktruck.2'}, {'loadtruck.2', 'boardtruck.2', 'unloadtruck.2'}, {'drivetruck.1', 'drivetruck.2', 'disembarktruck.2', 'loadtruck.2', 'boardtruck.2', 'unloadtruck.2'}]\n"
     ]
    }
   ],
   "source": [
    "HS_list = []\n",
    "ct_list = []\n",
    "\n",
    "# for transition set of each class\n",
    "for index, ts_class in enumerate(transition_sets_per_class):\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    \n",
    "    ct_per_class = []\n",
    "    HS_per_class = []\n",
    "    \n",
    "    # for transition set of each fsm in a class\n",
    "    for fsm_no, ts in enumerate(ts_class):\n",
    "        printmd(\"#### FSM: \" + str(fsm_no) + \" Hypothesis Set\")\n",
    "        \n",
    "        # transition matrix for the ts\n",
    "        t_df = adjacency_matrix_list[index].loc[list(ts), list(ts)]\n",
    "        ct_in_fsm = set()  # find consecutive transition set for a state machine in a class.\n",
    "        for i in range(t_df.shape[0]):\n",
    "            for j in range(t_df.shape[1]):\n",
    "                if t_df.iloc[i, j] != 'hole':\n",
    "                    if t_df.iloc[i, j] > 0:\n",
    "                        ct_in_fsm.add((t_df.index[i], t_df.columns[j]))\n",
    "        \n",
    "        ct_per_class.append(ct_in_fsm)\n",
    "        \n",
    "        # add to hypothesis set\n",
    "        HS = set()\n",
    "        \n",
    "        # for each pair B.k and C.l in TS s.t. e(B.k) = S = s(C.l)\n",
    "        for ct in ct_in_fsm:\n",
    "            B = ct[0].split('.')[0] # action name of T1\n",
    "            k = int(ct[0].split('.')[1]) # argument index of T1\n",
    "            \n",
    "            C = ct[1].split('.')[0] # action name of T2\n",
    "            l = int(ct[1].split('.')[1]) # argument index of T2\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # When both actions B and C contain another argument of the same sort G' in position k' and l' respectively, \n",
    "            # we hypothesise that there may be a relation between sorts G and G'.\n",
    "            for seq in sequences:\n",
    "                for actarg_tuple in seq:\n",
    "                    arglist1 = []\n",
    "                    arglist2 = []\n",
    "                    if actarg_tuple[0] == B: #if action name is same as B\n",
    "                        arglist1 = actarg_tuple[1].copy()\n",
    "#                         arglist1.remove(actarg_tuple[1][k]) # remove k from arglist\n",
    "                        for actarg_tuple_prime in seq: #loop through seq again.\n",
    "                            if actarg_tuple_prime[0] == C:\n",
    "                                arglist2 = actarg_tuple_prime[1].copy()\n",
    "#                                 arglist2.remove(actarg_tuple_prime[1][l]) # remove l from arglist\n",
    "                                \n",
    "\n",
    "                        # for arg lists of actions B and C, if class is same add a hypothesis set.\n",
    "                        for i in range(len(arglist1)): # if len is 0, we don't go in\n",
    "                            for j in range(len(arglist2)):\n",
    "                                class1 = get_class_index(arglist1[i], classes)\n",
    "                                class2 = get_class_index(arglist2[j], classes)\n",
    "                                if class1 == class2: # if object at same position have same classes\n",
    "                                    # add hypothesis to hypothesis set.\n",
    "                                    if (k!=i) and (l!=j):\n",
    "                                        HS.add((frozenset({\"e(\"+B+\".\"+ str(k)+\")\", \"s(\"+C+\".\"+str(l)+\")\"}),B,k,i,C,l,j,class_names[index],class_names[class1]))\n",
    "        print(str(len(HS))+ \" hypothesis created\")\n",
    "#         for h in HS:\n",
    "#             print(h)\n",
    "        \n",
    "        HS_per_class.append(HS)\n",
    "    HS_list.append(HS_per_class)\n",
    "    ct_list.append(ct_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test hyp against E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HS_list_retained = []\n",
    "for index, HS_class in enumerate(HS_list):\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    HS_per_class_retained = []\n",
    "\n",
    "\n",
    "    for fsm_no, HS in enumerate(HS_class):\n",
    "        printmd(\"#### FSM: \" + str(fsm_no) + \" Hypothesis Set\")\n",
    "\n",
    "        count=0\n",
    "        HS_copy = HS.copy()\n",
    "        HS_copy2 = HS.copy()\n",
    "\n",
    "        \n",
    "        # for each object O occuring in Ou\n",
    "        for O in arguments:\n",
    "            #   for each pair of transitions Ap.m and Aq.n consecutive for O in seq\n",
    "            ct = []\n",
    "            for seq in sequences:\n",
    "                for actarg_tuple in seq:\n",
    "                    act = actarg_tuple[0]\n",
    "                    for j, arg in enumerate(actarg_tuple[1]):\n",
    "                        if arg == O:\n",
    "                            ct.append((act + '.' + str(j), actarg_tuple[1]))\n",
    "\n",
    "\n",
    "            for i in range(len(ct)-1):\n",
    "                A_p = ct[i][0].split('.')[0]\n",
    "                m = int(ct[i][0].split('.')[1])\n",
    "                A_q = ct[i+1][0].split('.')[0]\n",
    "                n = int(ct[i+1][0].split('.')[1]) \n",
    "\n",
    "                # for each hypothesis H s.t. A_p = B, m = k, A_q = C, n = l\n",
    "\n",
    "                for H in HS_copy2:\n",
    "                    if A_p == H[1] and m == H[2] and A_q == H[4] and n == H[5]:\n",
    "                        k_prime = H[3]\n",
    "                        l_prime = H[6]\n",
    "\n",
    "                        # if O_p,k_prime = Q_q,l_prime\n",
    "                        if ct[i][1][k_prime] != ct[i+1][1][l_prime]:\n",
    "                            if H in HS_copy:\n",
    "                                HS_copy.remove(H)\n",
    "                                count += 1\n",
    "\n",
    "        print(str(len(HS_copy))+ \" hypothesis retained\")\n",
    "        # state machine\n",
    "#         if len(HS_copy)>0:\n",
    "#             plot_cytographs_fsm(state_machines_overall_list[index][fsm_no],domain_name)\n",
    "#         for H in HS_copy:\n",
    "#             print(H)\n",
    "        HS_per_class_retained.append(HS_copy)\n",
    "    HS_list_retained.append(HS_per_class_retained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Creation and merging of state parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: creating and merging state params\n"
     ]
    }
   ],
   "source": [
    "# Each hypothesis refers to an incoming and outgoing transition \n",
    "# through a particular state of an FSM\n",
    "# and matching associated transitions can be considered\n",
    "# to set and read parameters of a state.\n",
    "# Since there maybe multiple transitions through a give state,\n",
    "# it is possible for the same parameter to have multiple\n",
    "# pairwise occurences.\n",
    "\n",
    "print(\"Step 6: creating and merging state params\")\n",
    "param_bindings_list_overall = []\n",
    "for classindex, HS_per_class in enumerate(HS_list_retained):\n",
    "    param_bind_per_class = []\n",
    "    \n",
    "    \n",
    "    for fsm_no, HS_per_fsm in enumerate(HS_per_class):\n",
    "        param_binding_list = []\n",
    "        \n",
    "        # fsm in consideration\n",
    "        G = state_machines_overall_list[classindex][fsm_no]\n",
    "        state_list = G.nodes()\n",
    "        \n",
    "        # creation\n",
    "        for index,h in enumerate(HS_per_fsm):\n",
    "            param_binding_list.append((h,\"v\"+str(index)))\n",
    "        \n",
    "        merge_pl = [] # parameter to merge list\n",
    "        if len(param_binding_list)>1:\n",
    "            # merging\n",
    "            pairs = findsubsets(param_binding_list, 2)\n",
    "            for pair in pairs:\n",
    "                h_1 = pair[0][0]\n",
    "                h_2 = pair[1][0]\n",
    "                \n",
    "                \n",
    "                # equate states\n",
    "                state_eq_flag = False\n",
    "                for s_index, state in enumerate(state_list):\n",
    "                    # if both hyp states appear in single state in fsm\n",
    "                    if list(h_1[0])[0] in state:\n",
    "                        if list(h_1[0])[0] in state:\n",
    "                            state_eq_flag =True\n",
    "                            \n",
    "                \n",
    "                if ((state_eq_flag and h_1[1] == h_2[1] and h_1[2] == h_2[2] and h_1[3] == h_2[3]) or (state_eq_flag and h_1[4] == h_2[4] and h_1[5] == h_2[5] and h_1[6] == h_2[6])):\n",
    "                    merge_pl.append(list([pair[0][1], pair[1][1]]))\n",
    "          \n",
    "        \n",
    "       \n",
    "        #inner lists to sets (to list of sets)\n",
    "        l=[set(x) for x in merge_pl]\n",
    "\n",
    "        #cartesian product merging elements if some element in common\n",
    "        for a,b in itertools.product(l,l):\n",
    "            if a.intersection( b ):\n",
    "                a.update(b)\n",
    "                b.update(a)\n",
    "\n",
    "        #back to list of lists\n",
    "        l = sorted( [sorted(list(x)) for x in l])\n",
    "\n",
    "        #remove dups\n",
    "        merge_pl = list(l for l,_ in itertools.groupby(l))\n",
    "        \n",
    "        # sort\n",
    "        for pos, l in enumerate(merge_pl):\n",
    "            merge_pl[pos] = sorted(l, key = lambda x: int(x[1:]))\n",
    "        \n",
    "        print(merge_pl) # equal params appear in a list in this list.\n",
    "          \n",
    "            \n",
    "        for z,pb in enumerate(param_binding_list):\n",
    "            for l in merge_pl:\n",
    "                if pb[1] in l:\n",
    "                    # update pb\n",
    "                    param_binding_list[z] = (param_binding_list[z][0], l[0])\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "        param_bind_per_class.append(param_binding_list)\n",
    "        print(class_names[classindex])\n",
    "        \n",
    "        # set of params per class\n",
    "        param = set()\n",
    "        for pb in param_binding_list:\n",
    "#             print(pb)\n",
    "            param.add(pb[1])\n",
    "            \n",
    "        # num of params per class\n",
    "        printmd(\"No. of params earlier:\" + str(len(param_binding_list)))\n",
    "        printmd(\"No. of params after merging:\" + str(len(param)))\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    param_bindings_list_overall.append(param_bind_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Remove Parameter Flaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing State Params.\n",
    "# Flaw occurs Object can reach state S with param P having an inderminate value.\n",
    "# There is transition s.t. end(B.k) = S. \n",
    "# but there is no h = <S,B,k,k',C,l,l',G,G') and <h,P> is in bindings.\n",
    "\n",
    "para_bind_overall_fault_removed  = []\n",
    "for classindex, fsm_per_class in enumerate(state_machines_overall_list):\n",
    "    print(class_names[classindex])\n",
    "    pb_per_class_fault_removed = []\n",
    "\n",
    "    for fsm_no, G in enumerate(fsm_per_class):\n",
    "        \n",
    "        pb_per_fsm_fault_removed = []\n",
    "        # G is fsm in consideration\n",
    "        faulty_pb = []\n",
    "        for state in G.nodes():\n",
    "            inedges = G.in_edges(state, data=True)\n",
    "            \n",
    "            for ie in inedges:\n",
    "                tr = ie[2]['weight']\n",
    "                t_list = tr.split('|')\n",
    "                for t in t_list:\n",
    "                    B = t.split('.')[0]\n",
    "                    k = t.split('.')[1]\n",
    "                    S = 'e(' + t + ')'\n",
    "                    flaw = True\n",
    "                    for pb in param_bindings_list_overall[classindex][fsm_no]:\n",
    "                        H = pb[0]\n",
    "                        v = pb[1]\n",
    "                        if (S in set(H[0])) and (B==H[1]) and (int(k)==H[2]) :\n",
    "                            # this pb is okay\n",
    "                            flaw=False\n",
    "#                     print(flaw)\n",
    "                    if flaw:\n",
    "                        for pb in param_bindings_list_overall[classindex][fsm_no]:\n",
    "                            H = pb[0]\n",
    "                            H_states = list(H[0])\n",
    "                            for h_state in H_states:\n",
    "                                if h_state in state:\n",
    "                                    if pb not in faulty_pb:\n",
    "                                        faulty_pb.append(pb) # no duplicates\n",
    "        \n",
    "        for pb in param_bindings_list_overall[classindex][fsm_no]:\n",
    "            if pb not in faulty_pb:\n",
    "                pb_per_fsm_fault_removed.append(pb)\n",
    "        \n",
    "                                \n",
    "                        \n",
    "                        \n",
    "        print(str(len(pb_per_fsm_fault_removed)) + \"/\" + str(len(param_bindings_list_overall[classindex][fsm_no])) + \" param retained\")\n",
    "        for pb in pb_per_fsm_fault_removed:\n",
    "            print(pb)\n",
    "\n",
    "                \n",
    "        \n",
    "        pb_per_class_fault_removed.append(pb_per_fsm_fault_removed)\n",
    "    para_bind_overall_fault_removed.append(pb_per_class_fault_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: (TODO) Static Preconditions via LOP\n",
    "As further enhancement, one can add step 8: Extraction of static preconditions from the LOCM paper.\n",
    "However, LOP algorithm is better version of that step.\n",
    "\n",
    "Insert [LOP](https://www.aaai.org/ocs/index.php/ICAPS/ICAPS15/paper/viewFile/10621/10401) here for finding static preconditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9:  Formation of PDDL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;********************Learned PDDL domain******************\n",
      "(define  (domain driverlog)\n",
      "  (:requirements :typing)\n",
      "  (:types driver truck package location)\n",
      "  (:predicates\n",
      "    (driver_fsm0_state0)\n",
      "    (driver_fsm0_state1)    (truck_fsm0_state0)    (truck_fsm0_state1)    (truck_fsm0_state2)\n",
      "    (truck_fsm0_state3)    (truck_fsm0_state4)    (truck_fsm1_state0)    (truck_fsm1_state1)\n",
      "    (truck_fsm1_state2)    (truck_fsm1_state3)    (truck_fsm2_state0)    (truck_fsm2_state1)\n",
      "    (truck_fsm2_state2)    (truck_fsm2_state3)    (truck_fsm2_state4)    (truck_fsm3_state0)\n",
      "    (truck_fsm3_state1)    (package_fsm0_state0)    (package_fsm0_state1)    (package_fsm0_state2)\n",
      "    (location_fsm0_state0)    (location_fsm0_state1)    (location_fsm0_state2)    (location_fsm0_state3)\n",
      "    (location_fsm1_state0)    (location_fsm1_state1)    (location_fsm1_state2)    (location_fsm2_state0)\n",
      "    (location_fsm2_state1)    (location_fsm2_state2)    (location_fsm2_state3)    (location_fsm2_state4)\n",
      "    (location_fsm3_state0)    (location_fsm3_state1)    (location_fsm3_state2)    (location_fsm3_state3)\n",
      "    (location_fsm3_state4)    (location_fsm4_state0)    (location_fsm4_state1)  )\n",
      "  (:action  loadtruck   :parameters  (?package5 - package ?truck2 - truck ?s4 - location )\n",
      "   :precondition   (and\n",
      "        (package_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (package_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "  ))\n",
      "  (:action  drivetruck   :parameters  (?truck2 - truck ?s4 - location ?s1 - location ?driver1 - driver )\n",
      "   :precondition   (and\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "        (driver_fsm0_state0)\n",
      "        (driver_fsm0_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "        (driver_fsm0_state0)\n",
      "        (driver_fsm0_state1)\n",
      "  ))\n",
      "  (:action  unloadtruck   :parameters  (?package5 - package ?truck2 - truck ?s3 - location )\n",
      "   :precondition   (and\n",
      "        (package_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (package_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "  ))\n",
      "  (:action  disembarktruck   :parameters  (?driver1 - driver ?truck2 - truck ?s1 - location )\n",
      "   :precondition   (and\n",
      "        (driver_fsm0_state0)\n",
      "        (driver_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (driver_fsm0_state0)\n",
      "        (driver_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "  ))\n",
      "  (:action  boardtruck   :parameters  (?driver1 - driver ?truck2 - truck ?s4 - location )\n",
      "   :precondition   (and\n",
      "        (driver_fsm0_state0)\n",
      "        (driver_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "   )\n",
      "   :effect   (and\n",
      "        (driver_fsm0_state0)\n",
      "        (driver_fsm0_state1)\n",
      "        (truck_fsm0_state3)\n",
      "        (truck_fsm1_state2)\n",
      "        (truck_fsm1_state3)\n",
      "        (truck_fsm2_state4)\n",
      "        (truck_fsm3_state0)\n",
      "        (truck_fsm3_state1)\n",
      "        (location_fsm0_state3)\n",
      "        (location_fsm1_state0)\n",
      "        (location_fsm1_state2)\n",
      "        (location_fsm2_state2)\n",
      "        (location_fsm3_state3)\n",
      "        (location_fsm4_state0)\n",
      "        (location_fsm4_state1)\n",
      "  ))\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get action schema\n",
    "print(\";;********************Learned PDDL domain******************\")\n",
    "output_file = \"output/\"+ domain_name + \"/\" +  domain_name + \".pddl\"\n",
    "write_file = open(output_file, 'w')\n",
    "write_line = \"(define\"\n",
    "write_line += \"  (domain \"+ domain_name+\")\\n\"\n",
    "write_line += \"  (:requirements :typing)\\n\"\n",
    "write_line += \"  (:types\"\n",
    "for class_name in class_names:\n",
    "    write_line += \" \" + class_name\n",
    "write_line += \")\\n\"\n",
    "write_line += \"  (:predicates\\n\"\n",
    "\n",
    "# one predicate to represent each object state\n",
    "\n",
    "predicates = []\n",
    "for class_index, pb_per_class in enumerate(para_bind_overall_fault_removed):\n",
    "    for fsm_no, pbs_per_fsm in enumerate(pb_per_class):\n",
    "        for state_index, state in enumerate(state_machines_overall_list[class_index][fsm_no].nodes()):\n",
    "            \n",
    "            state_set = set(state.split('|'))\n",
    "            predicate = \"\"\n",
    "       \n",
    "            write_line += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_\" +  state\n",
    "            predicate += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_\" + state\n",
    "            for pb in pbs_per_fsm:\n",
    "                    if set(pb[0][0]) <= state_set:\n",
    "                        if \" ?\"+pb[1] + \" - \" + str(pb[0][8]) not in predicate:\n",
    "                            write_line += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "                            predicate += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "    \n",
    "            write_line += \")\\n\"\n",
    "            predicate += \")\"\n",
    "            predicates.append(predicate)\n",
    "write_line += \"  )\\n\"\n",
    "            \n",
    "for action_index, action in enumerate(actions):\n",
    "    write_line += \"\\n\"\n",
    "    write_line += \"  (:action\"\n",
    "    write_line += \"  \" + action + \" \"\n",
    "    write_line += \"  :parameters\"\n",
    "    write_line += \"  (\"\n",
    "    arg_already_written_flag = False\n",
    "    params_per_action = []\n",
    "    args_per_action = []\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            if not arg_already_written_flag:\n",
    "                if actarg_tuple[0] == action:\n",
    "                    arglist = []\n",
    "                    for arg in actarg_tuple[1]:\n",
    "                        write_line += \"?\"+arg + \" - \" + class_names[get_class_index(arg,classes)] + \" \"\n",
    "                        arglist.append(arg)\n",
    "                    args_per_action.append(arglist)\n",
    "                    params_per_action.append(actarg_tuple[1])\n",
    "                    arg_already_written_flag = True\n",
    "    write_line += \")\\n\"\n",
    "\n",
    "\n",
    "    # need to use FSMS to get preconditions and effects.\n",
    "    # Start-state = precondition. End state= Effect\n",
    "    preconditions = []\n",
    "    effects = []\n",
    "    for arglist in params_per_action:\n",
    "        for arg in arglist:\n",
    "            current_class_index = get_class_index(arg, classes)\n",
    "            for fsm_no, G in enumerate(state_machines_overall_list[current_class_index]):\n",
    "#                \n",
    "                for start, end, weight in G.edges(data='weight'):\n",
    "                    _actions = weight.split('|')\n",
    "                    for _action in _actions:\n",
    "                        \n",
    "                        if _action.split('.')[0] == action:\n",
    "                            for predicate in predicates:\n",
    "                                pred = predicate.split()[0].lstrip(\"(\")\n",
    "                                clss = pred.split('_')[0]\n",
    "                                fsm = pred.split('_')[1]\n",
    "                                state = set(pred.split('_')[2].replace('))',')').split('|'))\n",
    "\n",
    "\n",
    "\n",
    "                                if clss == class_names[current_class_index]:\n",
    "                                    if fsm == \"fsm\" + str(fsm_no):\n",
    "\n",
    "                                        if state == set(start.split('|')):\n",
    "\n",
    "                                            if predicate not in preconditions:\n",
    "                                                preconditions.append(predicate)\n",
    "\n",
    "                                        if state == set(end.split('|')):\n",
    "                                            if predicate not in effects:\n",
    "                                                effects.append(predicate)\n",
    "                            break\n",
    "                                        \n",
    "    \n",
    "                \n",
    "\n",
    "    write_line += \"   :precondition\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for precondition in preconditions:\n",
    "        # precondition = precondition.replace(?)\n",
    "        write_line += \"    \"+precondition+\"\\n\"\n",
    "    write_line += \"   )\\n\"\n",
    "    write_line += \"   :effect\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for effect in effects:\n",
    "        write_line += \"    \" + effect + \"\\n\"\n",
    "    write_line += \"  )\"\n",
    "\n",
    "    write_line += \")\\n\"\n",
    "\n",
    "write_line += \")\\n\" #domain ending bracket\n",
    "\n",
    "\n",
    "print(write_line)\n",
    "\n",
    "write_file.write(write_line)\n",
    "write_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating PDDL -- Fixing Syntax by replacing predicates with state dictionary values\n",
    "This is required because PDDL syntax doesn't support extra paranthesis () which occur in states (transitions occuring in states as 'start(t1)' or  'end(t1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get action schema\n",
    "print(\";;********************Learned PDDL domain******************\")\n",
    "output_file = \"output/\"+ domain_name + \"/\" +  domain_name + \".pddl\"\n",
    "write_file = open(output_file, 'w')\n",
    "write_line = \"(define\"\n",
    "write_line += \"  (domain \"+ domain_name+\")\\n\"\n",
    "write_line += \"  (:requirements :typing)\\n\"\n",
    "write_line += \"  (:types\"\n",
    "for class_name in class_names:\n",
    "    write_line += \" \" + class_name\n",
    "write_line += \")\\n\"\n",
    "write_line += \"  (:predicates\\n\"\n",
    "\n",
    "# one predicate to represent each object state\n",
    "\n",
    "predicates = []\n",
    "for class_index, pb_per_class in enumerate(para_bind_overall_fault_removed):\n",
    "    for fsm_no, pbs_per_fsm in enumerate(pb_per_class):\n",
    "        state_mapping = state_mappings_class[class_index][fsm_no]\n",
    "        \n",
    "        for state_index, state in enumerate(state_machines_overall_list[class_index][fsm_no].nodes()):\n",
    "            \n",
    "            state_set = set(state.split('|'))\n",
    "            predicate = \"\"\n",
    "       \n",
    "            write_line += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_state\" +  str(state_mapping[state])\n",
    "            predicate += \"    (\" + class_names[class_index] + \"_fsm\" + str(fsm_no) + \"_state\" + str(state_mapping[state])\n",
    "            for pb in pbs_per_fsm:\n",
    "                    if set(pb[0][0]) <= state_set:\n",
    "                        if \" ?\"+pb[1] + \" - \" + str(pb[0][8]) not in predicate:\n",
    "                            write_line += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "                            predicate += \" ?\"+pb[1] + \" - \" + str(pb[0][8])\n",
    "    \n",
    "            write_line += \")\\n\"\n",
    "            predicate += \")\"\n",
    "            predicates.append(predicate)\n",
    "write_line += \"  )\\n\"\n",
    "            \n",
    "for action_index, action in enumerate(actions):\n",
    "    write_line += \"  (:action\"\n",
    "    write_line += \"  \" + action + \" \"\n",
    "    write_line += \"  :parameters\"\n",
    "    write_line += \"  (\"\n",
    "    arg_already_written_flag = False\n",
    "    params_per_action = []\n",
    "    args_per_action = []\n",
    "    for seq in sequences:\n",
    "        for actarg_tuple in seq:\n",
    "            if not arg_already_written_flag:\n",
    "                if actarg_tuple[0] == action:\n",
    "                    arglist = []\n",
    "                    for arg in actarg_tuple[1]:\n",
    "                        write_line += \"?\"+arg + \" - \" + class_names[get_class_index(arg,classes)] + \" \"\n",
    "                        arglist.append(arg)\n",
    "                    args_per_action.append(arglist)\n",
    "                    params_per_action.append(actarg_tuple[1])\n",
    "                    arg_already_written_flag = True\n",
    "    write_line += \")\\n\"\n",
    "\n",
    "\n",
    "    # need to use FSMS to get preconditions and effects.\n",
    "    # Start-state = precondition. End state= Effect\n",
    "    preconditions = []\n",
    "    effects = []\n",
    "    for arglist in params_per_action:\n",
    "        for arg in arglist:\n",
    "            current_class_index = get_class_index(arg, classes)\n",
    "            for fsm_no, G in enumerate(state_machines_overall_list[current_class_index]):\n",
    "                G_int = state_machines_overall_list_2[current_class_index][fsm_no]\n",
    "                state_mapping = state_mappings_class[current_class_index][fsm_no]\n",
    "                for start, end, weight in G_int.edges(data='weight'):\n",
    "                    _actions = weight.split('|')\n",
    "                    for _action in _actions:\n",
    "                        if _action.split('.')[0] == action:\n",
    "                            for predicate in predicates:\n",
    "                                pred = predicate.split()[0].lstrip(\"(\")\n",
    "                                clss = pred.split('_')[0]\n",
    "                                fsm = pred.split('_')[1]\n",
    "                                state_ind = pred.split('_')[2].rstrip(\")\")[-1]\n",
    "\n",
    "                                if clss == class_names[current_class_index]:\n",
    "                                    if fsm == \"fsm\" + str(fsm_no):\n",
    "                                        if int(state_ind) == int(start):\n",
    "                                            if predicate not in preconditions:\n",
    "                                                preconditions.append(predicate)\n",
    "                                                \n",
    "                                        if int(state_ind) == int(end):\n",
    "                                            if predicate not in effects:\n",
    "                                                effects.append(predicate)\n",
    "                            break\n",
    "                            \n",
    "\n",
    "                \n",
    "\n",
    "    write_line += \"   :precondition\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for precondition in preconditions:\n",
    "        write_line += \"    \"+precondition+\"\\n\"\n",
    "    write_line += \"   )\\n\"\n",
    "    write_line += \"   :effect\"\n",
    "    write_line += \"   (and\\n\"\n",
    "    for effect in effects:\n",
    "        write_line += \"    \" + effect + \"\\n\"\n",
    "    write_line += \"  )\"\n",
    "\n",
    "    write_line += \")\\n\\n\"\n",
    "\n",
    "write_line += \")\\n\" #domain ending bracket\n",
    "\n",
    "\n",
    "print(write_line)\n",
    "\n",
    "write_file.write(write_line)\n",
    "write_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Mapping: What are these states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see what these states are, look at the following graphs\n",
    "\n",
    "for index, fsm_graphs in enumerate(state_machines_overall_list):\n",
    "    printmd(\"## Class \" + str(index))\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "    print(\"Number of FSMS:\" + str(num_fsms))\n",
    "    \n",
    "    for fsm_no, G in enumerate(fsm_graphs):  \n",
    "        printmd(\"Fsm \"+ str(fsm_no))\n",
    "        plot_cytographs_fsm(state_machines_overall_list_2[index][fsm_no], domain_name)\n",
    "        plot_cytographs_fsm(G, domain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Mappings: Text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sm_fsm in enumerate(state_mappings_class):\n",
    "    printmd(\"## Class \" + str(index))\n",
    "    printmd(\"### \"+ class_names[index])\n",
    "\n",
    "    \n",
    "    for fsm_no, mapping in enumerate(sm_fsm):\n",
    "        printmd(\"Fsm \"+ str(fsm_no))\n",
    "        pprint(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding entities using spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(coref_resolved_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">CURIOSITY MARS MISSION TRANSCRIPT</br>The last stage of the launch vehicle gives the spacecraft a final push and spins the spacecraft up for our eight-and-a-half month cruise to the red planet.</br>\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    10 minutes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " before hitting the atmosphere the cruise stage separates and final preparations for entry begin.</br>Hitting the atmosphere at \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    about 13000 miles per hour\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ", the spacecraft begins to slow down. While slowing down, the spacecraft uses thrusters to help steer toward the landing target.</br>We throw off weights to rebalance the spacecraft, so that the spacecraft’s lined for parachute deploy. After slowing to about Mach 2, or \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    about 1000 miles per hour\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ", we deploy the parachute to slow down even further.</br>Once we are below the speed of sound, the heat shield separates and the spacecraft looks for the ground with the landing radar.</br>Once we reach an altitude of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    about 1 mile\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ", the spacecraft drops out of the back-shell at \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    about 200 miles an hour\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ". the spacecraft then fires up the landing engine to slow the landing engine down even further.</br>Once we’ve descended to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    about 60 feet\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " above the ground, and going \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    only about 2 miles per hour\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ", the rover separates from the descent stage. As the rover is lowered, the wheels deploy in preparation for landing.</br>Once the rover is safely on the ground, and touchdown has been detected, the descent stage cuts the rover loose. the descent stage flies away leaving Curiosity safe on the surface of \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</br>One of the first things Curiosity does after landing is to deploy the mast, which supports many cameras and instruments. Curiosity shoots a laser at an interesting target. This helps us quickly understand the kind and</br>composition of an interesting target from a distance of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    up to 30 feet\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ".</br>If an interesting target is worth a closer look, the rover can drive up and inspect an interesting target with instruments and tools at the end of the rover arm.</br>The drill on its arm allows us to grab some of that rock and deliver some of that rock to the laboratory instruments inside the body of the rover.</br>the laboratory instruments inside the body of the rover can tell us even more about the mineral composition, getting us closer to understanding whether life could have existed on \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Mars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</br>Curiosity will be exploring the red planet for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    at least 2 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and there’s no telling what we will discover.\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(doc)), jupyter=True, style='ent', options = {'ents':['QUANTITY', 'TIME', 'LOC', 'DATE']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.4.2"
   }
  },
  "kernelspec": {
   "display_name": ".contextual_drl",
   "language": "python",
   "name": ".contextual_drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

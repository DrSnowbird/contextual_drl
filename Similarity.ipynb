{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(define (domain Tea)\n",
    "(:requirements :strips :typing :equality :durative-actions )\n",
    "(:types mug tea teaBag milk water )\n",
    "\n",
    "(:predicates\n",
    "(addedTo ?m - milk ?mu - mug)\n",
    "(atBottomOf ?t - teaBag ?m - mug)\n",
    "(containedIn ?w - water ?m - mug)\n",
    "(drinkMade ?t - tea)\n",
    "(haveDrink ?t - tea)\n",
    "(handempty)\n",
    "(atcafe)\n",
    "(handdirty)\n",
    "(nothanddirty)\n",
    ")\n",
    "\n",
    "\n",
    "(:durative-action buytea\n",
    ":parameters (?t - tea)\n",
    ":duration (= ?duration 15)\n",
    ":condition (and (at start (atcafe)) )\n",
    ":effect (and (at end (haveDrink ?t)) )\n",
    ")\n",
    "\n",
    "(:durative-action getMilk\n",
    ":parameters(?m - milk ?mu - mug)\n",
    ":duration (= ?duration 2)\n",
    ":condition (and (at start (handempty))))\n",
    ":effect(and (at start (addedTo ?m ?mu)) (at start (not (handempty)))\n",
    "(at end (handdirty)) (at end (not (nothanddirty))))\n",
    ")\n",
    "\n",
    "(:durative-action addWater\n",
    ":parameters (?w - water ?m - mug)\n",
    ":duration (= ?duration 2)\n",
    ":condition (and (at start (handempty))))\n",
    ":effect(and (at start (containedIn ?w ?m)) (at start (not (handempty)))\n",
    "(at end (handdirty)) )\n",
    ")\n",
    "\n",
    "(:durative-action addTeaBag\n",
    ":parameters (?t - teaBag ?m - mug)\n",
    ":duration (= ?duration 2)\n",
    ":condition (and (at start (handempty)) (over all(athome)))\n",
    ":effect(and (at start(atBottomOf ?t ?m)) (at start (not (handempty)))\n",
    "(at end (handdirty)) (at end (not (nothanddirty)) ))\n",
    ")\n",
    "\n",
    "(:durative-action clean\n",
    ":parameters ()\n",
    ":duration (= ?duration 1)\n",
    ":condition (and (at start (handdirty)) (over all(athome)))\n",
    ":effect (and (at start (nothanddirty)) (at start (not (handdirty)))\n",
    "(at end (handempty)))\n",
    ")\n",
    "\n",
    "(:durative-action mix\n",
    ":parameters (?t - teaBag ?w - water ?m - milk ?mu - mug ?te -tea)\n",
    ":duration (= ?duration 3)\n",
    ":condition (and (at start (handempty))(at start(addedTo ?m ?mu))\n",
    "(at start(atBottomOf ?t ?mu)) (at start(containedIn ?w ?mu))\n",
    "(over all(athome)))\n",
    ":effect (and (at end(drinkMade ?te)) (at start (not (handempty)))\n",
    "(at end (handempty)))\n",
    ")\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "(define (problem tempTeaProb)\n",
    "(:domain temporalTea)\n",
    "(:objects greenTeaBag - teaBag greenTea - tea someWater1 - water favouriteMug - mug soyaMilk - milk\n",
    ")\n",
    "\n",
    "(:init\n",
    "(handempty)\n",
    "(athome)\n",
    ")\n",
    "\n",
    "\n",
    "(:goal (and (athome) (drinkMade greenTea) ) )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Drop squished ginger into a pot of water turn on the stove.\n",
    "When the water starts to boil, put two and a half table spoons of sugar into the pot of boiling water.\n",
    "Wait for two minutes and put two spoons of tea if you like it medium strong, or two and a half spoons for strong or one and a half for light strong.\n",
    "After 3-4 minutes since adding the tea, then add milk.\n",
    "Wait 3 minutes after adding the Milk and then take the pot off the stove.\n",
    "put your strainer on a cup and pour the tea!\n",
    "Throw out the stuff left over in the strainer and pot.\n",
    "Pat yourself on the back and enjoy your Indian Tea!\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define domain Tea\n",
    "(:requirements :strips :typing :equality)\n",
    "(:types mug tea teaBag milk water)\n",
    "\n",
    "(:predicates\n",
    "(addedTo ?m - milk ?mu - mug)\n",
    "(atBottomOf ?t - teaBag ?m - mug)\n",
    "(containedIn ?w - water ?m - mug)\n",
    "(drinkMade ?t - tea)\n",
    "(haveDrink ?t - tea)\n",
    "(handempty)\n",
    ")\n",
    "\n",
    "\n",
    "action getMilk\n",
    "parameters(?m - milk ?mu - mug)\n",
    "condition (and (at start (handempty)))\n",
    "effect (and (at start (addedTo ?m ?mu)) (at start (not (handempty))) \n",
    "\n",
    "action addWater\n",
    ":parameters (?w - water ?m - mug)\n",
    ":condition (and (at start (handempty))))\n",
    ":effect(and (at start (containedIn ?w ?m)) (at start (not (handempty))) \n",
    "\n",
    "action addTeaBag\n",
    ":parameters (?t - teaBag ?m - mug)\n",
    ":condition (and (at start (handempty))\n",
    ":effect(and (at start(atBottomOf ?t ?m)) (at start (not (handempty)))\n",
    "\n",
    "action mix\n",
    ":parameters (?t - teaBag ?w - water ?m - milk ?mu - mug ?te -tea)\n",
    ":condition (and (at start (handempty))(at start(addedTo ?m ?mu))\n",
    "(at start(atBottomOf ?t ?mu)) (at start(containedIn ?w ?mu))\n",
    ":effect (and (at end(drinkMade ?te)) (at start (not (handempty)))\n",
    "(at end (handempty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Get milk and add it to the mug.\n",
    "Get water and add water to the mug that contains milk.\n",
    "Get teabag and place it at the bottom of the mug.\n",
    "Mix the teabag, water, milk in the mug.\n",
    "Remove the teabag and the drink is ready.\n",
    "Drink the tea.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human annotations\n",
    "----------------------\n",
    "\n",
    "- get(milk)\n",
    "- add(milk,mug)\n",
    "- get(water)\n",
    "- add(water,mug)\n",
    "- get(teabag)\n",
    "- place(teabag, mug)\n",
    "- mix(teabag,water,milk)\n",
    "- remove(teabag)\n",
    "- drink(tea)\n",
    "\n",
    "LOCM fails on this. It over-generalizes and would have actions add,get,place,mix,remove,drink. It will learn you add something to the cup ..don't know what, mix them and can remove them and then drink the tea.\n",
    "\n",
    "LOCM will work with restrictive templates (like the Framer paper.)\n",
    "\n",
    "So can I say that user would differentiate these actions: add-water, add-milk.\n",
    "\n",
    "\n",
    "The automatic to differentiate the action names:\n",
    "-------------------------------------------------------\n",
    "Way 1.0\n",
    "- Get pairs of actions with same names.\n",
    "- If number of arguments are different, name them action_name1, action_name2. This would be okay easy for the user to differentiate between in the final domain model even if they are \n",
    "- Go to argument one, if they are synonyms; change argument to that. Repeat for all arguments .. \n",
    "\n",
    "Way 2.0\n",
    "- Use sentence vectors to cluster similar sentences in the text. Replace all similar sentences with the one type of sentence.\n",
    "- As now we are sure that no two sentences represent the same action, we then employ the tactics of 1.0 to differentiate actions with same names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to check the quality of models?\n",
    "-------------------------------------\n",
    "\n",
    "- Syntax check is easy. Can just link it up to a PDDL editor and see if there are any red lines.\n",
    "\n",
    "\n",
    "##### Validity of the model\n",
    "There is no standard way to do this as the domain model would be outputted according to the text that is inputted. So a wide range of models are possible. If the text represents the domain model exactly (restrictive template), then it is possible to get somewhat useful model. We can argue that our aim is to get models of just about anything that is instructional to get some intelligent answers about stuff.\n",
    "\n",
    "\n",
    "Checking Validity using VAL\n",
    "\n",
    "- The plan validator is a tool that takes as input a planning problem, specified in PDDL, and a plan, and automatically checks if the plan is correct. The idea is to put in gold-standard model and see plan generated by our model is correct according to gold standard model or not.\n",
    "\n",
    "- So, user input is definitely required to fix it ?\n",
    "\n",
    "Another way is to bonkers -- user to the rescue!\n",
    "- User makes a plan looking at the domain model and original action sequences, and checks it using VAL to validate the model. \n",
    "##### Can include a transcript for this of what I thought.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the camera-lens using cloth.\n",
    "\n",
    "Set the resolution and picture quality of the phone to highest or set the resolution to default\n",
    "\n",
    "Turn off picture frames and effects\n",
    "\n",
    "Set the white-balance\n",
    "\n",
    "Adjust position of the phone to have sufficient light and the subject in the frame\n",
    "\n",
    "if the light is low, use your flash\n",
    "\n",
    "Click on capture button to take the picture\n",
    "\n",
    "If desired, save the picture to phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kitchen\n",
      "two kinds\n",
      "breads\n",
      "fillings\n",
      "a gluten-free sandwich\n",
      "gluten-free bread\n",
      "gluten-free filling\n",
      "the gluten-free sandwich\n",
      "a tray\n",
      "the tray\n",
      "kitchen\n",
      "the table-1\n",
      "the gluten-free sandwich\n",
      "the allergic child\n",
      "table-1\n",
      "a normal sandwich\n",
      "normal bread\n",
      "normal filling\n",
      "the sandwich\n",
      "a tray\n",
      "the tray\n",
      "kitchen\n",
      "the sandwich\n",
      "the non-allergic child\n",
      "table-2\n"
     ]
    }
   ],
   "source": [
    "text = u'''The kitchen has two kinds of breads and fillings\n",
    "Make a gluten-free sandwich using gluten-free bread and gluten-free filling\n",
    "Put the gluten-free sandwich on a tray\n",
    "Move the tray from kitchen to the table-1\n",
    "Serve the gluten-free sandwich to the allergic child sitting on table-1\n",
    "Make a normal sandwich which contains gluten with normal bread and normal filling\n",
    "Put the sandwich on a tray\n",
    "Move the tray from kitchen to the table-2\n",
    "Serve the sandwich which contains gluten to the non-allergic child sitting on table-2'''\n",
    "doc = nlp(text)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_sequence_childsnack = ['Make (gluten-free, sandwich5)',  \n",
    "'Put (gluten-free, sandwich5)',  \n",
    "'Move (tray7)',\n",
    "'Serve (gluten-free, sandwich5)',\n",
    "'Move (tray7)',                              \n",
    "'Make (sandwich2)',\n",
    "'Put (sandwich2)',\n",
    "'Move (tray5)',\n",
    "'Serve (sandwich2)',\n",
    "'Move (tray5)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_texts(texts):\n",
    "    # Load the annotation models\n",
    "    nlp = English()\n",
    "    # Stream texts through the models. We accumulate a buffer and release\n",
    "    # the GIL around the parser, for efficient multi-threading.\n",
    "    for doc in nlp.pipe(texts, n_threads=4):\n",
    "        # Iterate over base NPs, e.g. \"all their good ideas\"\n",
    "        for np in doc.noun_chunks:\n",
    "            # Only keep adjectives and nouns, e.g. \"good ideas\"\n",
    "            while len(np) > 1 and np[0].dep_ not in ('amod', 'compound'):\n",
    "                np = np[1:]\n",
    "            if len(np) > 1:\n",
    "                # Merge the tokens, e.g. good_ideas\n",
    "                np.merge(np.root.tag_, np.text, np.root.ent_type_)\n",
    "            # Iterate over named entities\n",
    "            for ent in doc.ents:\n",
    "                if len(ent) > 1:\n",
    "                    # Merge them into single tokens\n",
    "                    ent.merge(ent.root.tag_, ent.text, ent.label_)\n",
    "        token_strings = []\n",
    "        for token in tokens:\n",
    "            text = token.text.replace(' ', '_')\n",
    "            tag = token.ent_type_ or token.pos_\n",
    "            token_strings.append('%s|%s' % (text, tag))\n",
    "        yield ' '.join(token_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_doc = nlp(\"Make no gluten sandwich from no gluten bread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Make [ ROOT ]\n",
      "1 no [ det ]\n",
      "2 gluten [ amod ]\n",
      "3 sandwich [ dobj ]\n",
      "4 from [ prep ]\n",
      "5 no [ det ]\n",
      "6 gluten [ amod ]\n",
      "7 bread [ pobj ]\n"
     ]
    }
   ],
   "source": [
    "for token in example_doc:\n",
    "    print(token.i, token, \"[\", token.dep_, \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluten sandwich\n",
      "gluten bread\n"
     ]
    }
   ],
   "source": [
    "for tok in [tok for tok in example_doc if (tok.dep_ == 'compound' or tok.dep_ == 'amod')]: # Get list of \n",
    "    noun = example_doc[tok.i: tok.head.i + 1]\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = u'''Turn-off all hazardous experiments or procedures before evacuating.\n",
    "If possible, take or secure all valuables, wallets, purses, keys, etc as quickly as possible.\n",
    "Close all doors behind you as you exit.\n",
    "Check all doors for heat before you open or go through them to avoid walking into a fire.\n",
    "Evacuate the building using the nearest exit or stairway. Do not use the elevators.\n",
    "Call 911 from a safe area and provide name, location, and nature of emergency.\n",
    "Proceed to a pre-determined assembly area of building and remain there until you are told to re-enter by the emergency personnel in charge.\n",
    "Do not impede access of emergency personnel to the area.\n",
    "Inform Building Safety Personnel or Emergency Personnel of the event, conditions and location of individuals who require assistance and have not been evacuated.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_seq = u\"Autonomous cars shift insurance liability toward manufacturers\"\n",
    "\n",
    "doc = nlp(input_seq)\n",
    "for chunk in doc.noun_chunks:\n",
    "    if chunk.text in input_seq:\n",
    "        input_seq = input_seq.replace(chunk.text, chunk.text.replace(' ','-'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn-off all-hazardous-experiments or procedures before evacuating.\n",
      "If possible, take or secure all-valuables, wallets, purses, keys, etc as quickly as possible.\n",
      "Close all-doors behind you as you exit.\n",
      "Check all-doors for heat before you open or go through them to avoid walking into a-fire.\n",
      "Evacuate the-building using the-nearest-exit or stairway. Do not use the-elevators.\n",
      "Call 911 from a-safe-area and provide name, location, and nature of emergency.\n",
      "Proceed to a-pre-determined-assembly-area of building and remain there until you are told to re-enter by the-emergency-personnel in charge.\n",
      "Do not impede access of emergency-personnel to the-area.\n",
      "Inform-Building-Safety-Personnel or Emergency-Personnel of the-event, conditions and location of individuals who require assistance and have not been evacuated.\n"
     ]
    }
   ],
   "source": [
    "print(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = u'''TURN OFF ALL HAZARDOUS EXPERIMENTS or procedures before evacuating\n",
    "If possible, take or secure all valuables, wallets, purses, keys, etc as quickly as possible\n",
    "CLOSE all doors behind you as you exit\n",
    "CHECK all doors for heat before you open or go through them to avoid walking into a fire\n",
    "EVACUATE the building using the nearest exit or stairway. DO NOT USE ELEVATORS\n",
    "CALL 911 or CALL fire department from a safe area and provide name, location, and nature of emergency\n",
    "PROCEED to pre-determined assembly area of building and remain there until you are told to re-enter by the emergency personnel in charge\n",
    "DO NOT IMPEDE access of emergency personnel to the area\n",
    "INFORM Building Safety Personnel or Emergency Personnel of the event, conditions and location of individuals who require assistance and have not been evacuated'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-f8cd953c547e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-f8cd953c547e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    NO1: TURN(1) OFF(2) ALL(3) HAZARDOUS(4) EXPERIMENTS(5) or(6) procedures(7) before(8) evacuating(9)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cooking, non_gui2\n",
    "NO1: TURN(1) OFF(2) ALL(3) HAZARDOUS(4) EXPERIMENTS(5) or(6) procedures(7) before(8) evacuating(9) \n",
    "<1>  evacuating (EXPERIMENTS, procedures)    \n",
    "\n",
    "NO2: If(1) possible(2) take(3) or(4) secure(5) all(6) valuables(7) wallets(8) purses(9) keys(10) etc(11) \n",
    "<2>  take (valuables)    <3>  secure (valuables, wallets, purses, keys)    \n",
    "\n",
    "NO3: as(1) quickly(2) as(3) possible(4) \n",
    "\n",
    "NO4: CLOSE(1) all(2) doors(3) behind(4) you(5) as(6) you(7) exit(8) \n",
    "<4>  CLOSE (doors)    \n",
    "\n",
    "NO5: CHECK(1) all(2) doors(3) for(4) heat(5) before(6) you(7) open(8) or(9) go(10) through(11) them(12) to(13) avoid(14) walking(15) into(16) a(17) fire(18) \n",
    "<5>  CHECK (doors)    \n",
    "\n",
    "NO6: EVACUATE(1) the(2) building(3) using(4) the(5) nearest(6) exit(7) or(8) stairway(9) \n",
    "<6>  EVACUATE (building)    <7>  using (nearest, exit, stairway)    \n",
    "\n",
    "NO7: Do(1) not(2) use(3) elevators(4) \n",
    "\n",
    "NO8: CALL(1) 911(2) from(3) a(4) safe(5) area(6) and(7) provide(8) name(9) location(10) and(11) nature(12) of(13) emergency(14) \n",
    "<8>  CALL (CALL, 911)    <9>  provide (name, location, nature)    \n",
    "\n",
    "NO9: PROCEED(1) to(2) pre-determined(3) assembly(4) area(5) of(6) building(7) and(8) remain(9) there(10) until(11) you(12) are(13) told(14) to(15) re-enter(16) by(17) the(18) emergency(19) personnel(20) in(21) charge(22) \n",
    "<10>  PROCEED (nature, PROCEED)    <11>  remain ()    <12>  re-enter ()    \n",
    "\n",
    "NO10: DO(1) NOT(2) IMPEDE(3) access(4) of(5) emergency(6) personnel(7) to(8) the(9) area(10) \n",
    "\n",
    "NO11: INFORM(1) Building(2) Safety(3) Personnel(4) or(5) Emergency(6) Personnel(7) of(8) the(9) event(10) conditions(11) and(12) location(13) of(14) individuals(15) who(16) require(17) assistance(18) and(19) have(20) not(21) been(22) evacuated(23) \n",
    "<13>  INFORM (access, personnel, INFORM, Building, Safety, Personnel, Emergency)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-b95b67633138>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-b95b67633138>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    NO1: TURN(1) OFF(2) ALL(3) HAZARDOUS(4) EXPERIMENTS(5) or(6) procedures(7) before(8) evacuating(9)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wikihow, non_gui2\n",
    "NO1: TURN(1) OFF(2) ALL(3) HAZARDOUS(4) EXPERIMENTS(5) or(6) procedures(7) before(8) evacuating(9) \n",
    "\n",
    "NO2: If(1) possible(2) take(3) or(4) secure(5) all(6) valuables(7) wallets(8) purses(9) keys(10) etc(11) as(12) quickly(13) as(14) possible(15) \n",
    "<1>  take (valuables, wallets)    <2>  secure (valuables, wallets)    \n",
    "\n",
    "NO3: CLOSE(1) all(2) doors(3) behind(4) you(5) as(6) you(7) exit(8) \n",
    "<3>  CLOSE (doors)    \n",
    "\n",
    "NO4: CHECK(1) all(2) doors(3) for(4) heat(5) before(6) you(7) open(8) or(9) go(10) through(11) them(12) to(13) avoid(14) walking(15) into(16) a(17) fire(18) \n",
    "<4>  CHECK (doors, heat)    <5>  avoid (walking)    \n",
    "\n",
    "NO5: EVACUATE(1) the(2) building(3) using(4) the(5) nearest(6) exit(7) or(8) stairway(9) \n",
    "<6>  EVACUATE (building)    <7>  using (nearest, exit)    \n",
    "\n",
    "NO6: Do(1) not(2) use(3) elevators(4) \n",
    "\n",
    "NO7: CALL(1) 911(2) from(3) a(4) safe(5) area(6) and(7) provide(8) name(9) location(10) and(11) nature(12) of(13) emergency(14) \n",
    "<8>  CALL (911)    <9>  provide (name, location)    \n",
    "\n",
    "NO8: PROCEED(1) to(2) pre-determined(3) assembly(4) area(5) of(6) building(7) and(8) remain(9) there(10) until(11) you(12) are(13) told(14) to(15) re-enter(16) by(17) the(18) emergency(19) personnel(20) in(21) charge(22) \n",
    "<10>  PROCEED (pre-determined, assembly, area)    <11>  remain (there)    \n",
    "\n",
    "NO9: DO(1) NOT(2) IMPEDE(3) access(4) of(5) emergency(6) personnel(7) to(8) the(9) area(10) \n",
    "\n",
    "NO10: INFORM(1) Building(2) Safety(3) Personnel(4) or(5) Emergency(6) Personnel(7) of(8) the(9) event(10) conditions(11) and(12) location(13) of(14) individuals(15) who(16) require(17) assistance(18) and(19) have(20) not(21) been(22) evacuated(23) \n",
    "<12>  INFORM (Building, Safety, Personnel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shivam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/shivam/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', '(my-name', 'is', \"8o'clock\", '350ºF']\n"
     ]
    }
   ],
   "source": [
    "tokens = ['hello', '(my-name', 'is', '8o\\'clock', '350ºF']\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello (my-name is 8o'clock 350ºF\n"
     ]
    }
   ],
   "source": [
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = SpaceTokenizer().tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', '(my-name', 'is', \"8o'clock\", '350ºF']\n"
     ]
    }
   ],
   "source": [
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'JJ'), ('(my-name', 'NN'), ('is', 'VBZ'), (\"8o'clock\", 'CD')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello|JJ', '(my-name|NN', 'is|VBZ', \"8o'clock|CD\"]\n"
     ]
    }
   ],
   "source": [
    "pos_list = nltk.pos_tag(tokens2)\n",
    "pos_list_joined = []\n",
    "for tup in pos_list:\n",
    "    tup = '|'.join(tup)\n",
    "    pos_list_joined.append(tup)\n",
    "print(pos_list_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello|JJ my-name|NN is|VBZ 8o'clock|CD\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(pos_list_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.simple import SpaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

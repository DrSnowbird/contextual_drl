
 Arguments:
action_rate: 0.1
agent_mode: arg
batch_size: 8
contextual_embedding: bert
dense_dim: 256
dis_dim: 3172
display_training_result: 0
domain: cooking
dropout: 0.5
epochs: 1
exploration_decay_steps: 1000
exploration_rate_end: 0.1
exploration_rate_start: 1
exploration_rate_test: 0.0
filter_act_ind: 1
gamma: 0.9
gui_mode: False
learning_rate: 0.001
load_replay: 0
load_weights: False
model_dim: 50
num_actions: 2
num_filters: 32
num_words: 128
object_rate: 0.07
optimizer: adam
positive_rate: 0.9
priority: 1
random_play: 0
replay_size: 50000
result_dir: results/cooking_arg_bert
reward_assign: [1, 2, 3]
reward_base: 50.0
save_replay: 0
save_replay_name: data/saved_replay_memory.pkl
save_replay_size: 1000
save_weights: True
stacked_embeddings: StackedEmbeddings [/home/nfs/smiglani/.flair/embeddings/glove.gensim,BertEmbeddings(
  (model): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): BertLayerNorm()
      (dropout): Dropout(p=0.1)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): BertLayerNorm()
            (dropout): Dropout(p=0.1)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
)]
start_epoch: 0
stop_epoch_gap: 5
tag_dim: 3172
target_steps: 5
test_steps: 64640
train_episodes: 50
train_frequency: 1
train_repeat: 1
train_steps: 206464
use_act_rate: 1
valid_steps: 51712
word2vec: <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f037159e5c0>
word_dim: 3172



Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 0
total_act: 567	 right_act: 48	 tagged_act: 256
acc: 0.933466	 rec: 0.084656	 pre: 0.187500	 f1: 0.116646

cumulative reward: 453705.421265	 average reward: 41.126307


 Best f1 value: {'rec': [0.0, 0.08465608465608465], 'pre': [0.0, 0.1875], 'f1': [0.0, 0.1166464155528554], 'rw': [0.0, 41.12630722123354]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 0
total_act: 567	 right_act: 0	 tagged_act: 0
acc: 0.947970	 rec: 0.000000	 pre: 0.000000	 f1: 0.000000

cumulative reward: 465708.000000	 average reward: 42.214286


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 0
total_act: 567	 right_act: 0	 tagged_act: 0
acc: 0.947970	 rec: 0.000000	 pre: 0.000000	 f1: 0.000000

cumulative reward: 465708.000000	 average reward: 42.214286


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 0
total_act: 567	 right_act: 31	 tagged_act: 62
acc: 0.947970	 rec: 0.054674	 pre: 0.500000	 f1: 0.098569

cumulative reward: 468708.152588	 average reward: 42.486236


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 0
total_act: 567	 right_act: 108	 tagged_act: 122
acc: 0.956490	 rec: 0.190476	 pre: 0.885246	 f1: 0.313498

cumulative reward: 485819.154175	 average reward: 44.037269


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047], 'pre': [0.0, 0.1875, 0.8852459016393442], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524], 'rw': [0.0, 41.12630722123354, 44.037269232669026]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 8
total_act: 567	 right_act: 400	 tagged_act: 1671
acc: 0.869743	 rec: 0.705467	 pre: 0.239378	 f1: 0.357462

cumulative reward: 411042.719849	 average reward: 37.259130


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 2
total_act: 567	 right_act: 295	 tagged_act: 388
acc: 0.966461	 rec: 0.520282	 pre: 0.760309	 f1: 0.617801

cumulative reward: 515561.863525	 average reward: 46.733309


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 4
total_act: 567	 right_act: 271	 tagged_act: 319
acc: 0.968727	 rec: 0.477954	 pre: 0.849530	 f1: 0.611738

cumulative reward: 515859.589966	 average reward: 46.760296


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 4
total_act: 567	 right_act: 331	 tagged_act: 455
acc: 0.967277	 rec: 0.583774	 pre: 0.727473	 f1: 0.647750

cumulative reward: 519986.506470	 average reward: 47.134382


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 4
total_act: 567	 right_act: 321	 tagged_act: 383
acc: 0.971991	 rec: 0.566138	 pre: 0.838120	 f1: 0.675789

cumulative reward: 524271.598633	 average reward: 47.522806


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 8
total_act: 567	 right_act: 389	 tagged_act: 765
acc: 0.949873	 rec: 0.686067	 pre: 0.508497	 f1: 0.584084

cumulative reward: 506330.088623	 average reward: 45.896491


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 7
total_act: 567	 right_act: 381	 tagged_act: 587
acc: 0.964558	 rec: 0.671958	 pre: 0.649063	 f1: 0.660312

cumulative reward: 522039.744385	 average reward: 47.320499


Summary:
total_ecs: 5	 right_ecs: 3	 tagged_ecs: 3
total_act: 567	 right_act: 231	 tagged_act: 245
acc: 0.968093	 rec: 0.407407	 pre: 0.942857	 f1: 0.568966

cumulative reward: 510538.883789	 average reward: 46.277999


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 4
total_act: 567	 right_act: 315	 tagged_act: 355
acc: 0.973441	 rec: 0.555556	 pre: 0.887324	 f1: 0.683297

cumulative reward: 525265.540894	 average reward: 47.612903


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 5
total_act: 567	 right_act: 327	 tagged_act: 381
acc: 0.973350	 rec: 0.576720	 pre: 0.858268	 f1: 0.689873

cumulative reward: 526371.446045	 average reward: 47.713148


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 4
total_act: 567	 right_act: 289	 tagged_act: 364
acc: 0.967912	 rec: 0.509700	 pre: 0.793956	 f1: 0.620838

cumulative reward: 516576.038940	 average reward: 46.825239


Summary:
total_ecs: 5	 right_ecs: 0	 tagged_ecs: 8
total_act: 567	 right_act: 384	 tagged_act: 629
acc: 0.961294	 rec: 0.677249	 pre: 0.610493	 f1: 0.642140

cumulative reward: 518487.727173	 average reward: 46.998525


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 6
total_act: 567	 right_act: 332	 tagged_act: 394
acc: 0.973078	 rec: 0.585538	 pre: 0.842640	 f1: 0.690947

cumulative reward: 526925.202759	 average reward: 47.763343


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767, 0.5855379188712522], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331, 0.8426395939086294], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519, 0.6909469302809573], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616, 47.76334325224701]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 6
total_act: 567	 right_act: 371	 tagged_act: 511
acc: 0.969543	 rec: 0.654321	 pre: 0.726027	 f1: 0.688312

cumulative reward: 526807.319458	 average reward: 47.752658


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 5
total_act: 567	 right_act: 344	 tagged_act: 416
acc: 0.973260	 rec: 0.606702	 pre: 0.826923	 f1: 0.699898

cumulative reward: 528274.986084	 average reward: 47.885695


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767, 0.5855379188712522, 0.6067019400352733], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331, 0.8426395939086294, 0.8269230769230769], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519, 0.6909469302809573, 0.6998982706002034], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616, 47.76334325224701, 47.88569489521251]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 8
total_act: 567	 right_act: 391	 tagged_act: 600
acc: 0.965283	 rec: 0.689594	 pre: 0.651667	 f1: 0.670094

cumulative reward: 523813.133057	 average reward: 47.481248


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 8
total_act: 567	 right_act: 367	 tagged_act: 488
acc: 0.971084	 rec: 0.647266	 pre: 0.752049	 f1: 0.695735

cumulative reward: 528097.874268	 average reward: 47.869641


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 8
total_act: 567	 right_act: 409	 tagged_act: 656
acc: 0.963470	 rec: 0.721340	 pre: 0.623476	 f1: 0.668847

cumulative reward: 522965.241821	 average reward: 47.404391


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 9
total_act: 567	 right_act: 388	 tagged_act: 534
acc: 0.970722	 rec: 0.684303	 pre: 0.726592	 f1: 0.704814

cumulative reward: 529717.481812	 average reward: 48.016450


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767, 0.5855379188712522, 0.6067019400352733, 0.6843033509700176], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331, 0.8426395939086294, 0.8269230769230769, 0.7265917602996255], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519, 0.6909469302809573, 0.6998982706002034, 0.7048138056312443], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616, 47.76334325224701, 47.88569489521251, 48.01645049052968]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 3	 tagged_ecs: 5
total_act: 567	 right_act: 356	 tagged_act: 420
acc: 0.975073	 rec: 0.627866	 pre: 0.847619	 f1: 0.721378

cumulative reward: 530884.034546	 average reward: 48.122193


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767, 0.5855379188712522, 0.6067019400352733, 0.6843033509700176, 0.6278659611992945], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331, 0.8426395939086294, 0.8269230769230769, 0.7265917602996255, 0.8476190476190476], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519, 0.6909469302809573, 0.6998982706002034, 0.7048138056312443, 0.7213779128672746], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616, 47.76334325224701, 47.88569489521251, 48.01645049052968, 48.122193124174984]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 6
total_act: 567	 right_act: 352	 tagged_act: 450
acc: 0.971719	 rec: 0.620811	 pre: 0.782222	 f1: 0.692232

cumulative reward: 526889.924438	 average reward: 47.760145


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 8
total_act: 567	 right_act: 427	 tagged_act: 633
acc: 0.968818	 rec: 0.753086	 pre: 0.674566	 f1: 0.711667

cumulative reward: 531349.784668	 average reward: 48.164411


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 8
total_act: 567	 right_act: 396	 tagged_act: 597
acc: 0.966461	 rec: 0.698413	 pre: 0.663317	 f1: 0.680412

cumulative reward: 524846.488770	 average reward: 47.574917


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 8
total_act: 567	 right_act: 403	 tagged_act: 582
acc: 0.969090	 rec: 0.710758	 pre: 0.692440	 f1: 0.701480

cumulative reward: 528533.122070	 average reward: 47.909094


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 6
total_act: 567	 right_act: 358	 tagged_act: 412
acc: 0.976251	 rec: 0.631393	 pre: 0.868932	 f1: 0.731359

cumulative reward: 532890.641602	 average reward: 48.304083


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767, 0.5855379188712522, 0.6067019400352733, 0.6843033509700176, 0.6278659611992945, 0.6313932980599647], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331, 0.8426395939086294, 0.8269230769230769, 0.7265917602996255, 0.8476190476190476, 0.8689320388349514], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519, 0.6909469302809573, 0.6998982706002034, 0.7048138056312443, 0.7213779128672746, 0.7313585291113381], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616, 47.76334325224701, 47.88569489521251, 48.01645049052968, 48.122193124174984, 48.3040828137747]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 2	 tagged_ecs: 7
total_act: 567	 right_act: 416	 tagged_act: 569
acc: 0.972534	 rec: 0.733686	 pre: 0.731107	 f1: 0.732394

cumulative reward: 534134.876831	 average reward: 48.416867


 Best f1 value: {'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767, 0.5855379188712522, 0.6067019400352733, 0.6843033509700176, 0.6278659611992945, 0.6313932980599647, 0.7336860670194003], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331, 0.8426395939086294, 0.8269230769230769, 0.7265917602996255, 0.8476190476190476, 0.8689320388349514, 0.7311072056239016], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519, 0.6909469302809573, 0.6998982706002034, 0.7048138056312443, 0.7213779128672746, 0.7313585291113381, 0.7323943661971831], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616, 47.76334325224701, 47.88569489521251, 48.01645049052968, 48.122193124174984, 48.3040828137747, 48.416867007891106]}  best epoch: 0


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 3
total_act: 567	 right_act: 291	 tagged_act: 314
acc: 0.972534	 rec: 0.513228	 pre: 0.926752	 f1: 0.660613

cumulative reward: 521850.098999	 average reward: 47.303308


Summary:
total_ecs: 5	 right_ecs: 1	 tagged_ecs: 8
total_act: 567	 right_act: 412	 tagged_act: 616
acc: 0.967640	 rec: 0.726631	 pre: 0.668831	 f1: 0.696534

cumulative reward: 528626.682861	 average reward: 47.917575


 training process:
{'rec': [0.0, 0.08465608465608465, 0.19047619047619047, 0.7054673721340388, 0.5202821869488536, 0.5837742504409171, 0.5661375661375662, 0.5555555555555556, 0.5767195767195767, 0.5855379188712522, 0.6067019400352733, 0.6843033509700176, 0.6278659611992945, 0.6313932980599647, 0.7336860670194003], 'pre': [0.0, 0.1875, 0.8852459016393442, 0.23937761819269898, 0.7603092783505154, 0.7274725274725274, 0.8381201044386423, 0.8873239436619719, 0.8582677165354331, 0.8426395939086294, 0.8269230769230769, 0.7265917602996255, 0.8476190476190476, 0.8689320388349514, 0.7311072056239016], 'f1': [0.0, 0.1166464155528554, 0.31349782293178524, 0.3574620196604111, 0.6178010471204188, 0.6477495107632094, 0.6757894736842105, 0.683297180043384, 0.689873417721519, 0.6909469302809573, 0.6998982706002034, 0.7048138056312443, 0.7213779128672746, 0.7313585291113381, 0.7323943661971831], 'rw': [0.0, 41.12630722123354, 44.037269232669026, 37.25912979048521, 46.73330887648574, 47.13438238485556, 47.52280625750657, 47.61290254655137, 47.71314775606616, 47.76334325224701, 47.88569489521251, 48.01645049052968, 48.122193124174984, 48.3040828137747, 48.416867007891106]}

rec: [0.7336860670194003]
pre: [0.7311072056239016]
f1: [0.7323943661971831]
rw: [48.416867007891106]

Avg f1: 0.7323943661971831  Avg reward: 48.416867007891106
